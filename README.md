# üöÄ GPT-2 Two-Phase Training System

–ü–æ–≤–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –¥–≤–æ—Ñ–∞–∑–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è GPT-2: Phase 1 (Language Pretraining) —Ç–∞ Phase 2 (Instruction Tuning) –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é Google Colab.

---

## üéØ –û—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ

- **–î–≤–æ—Ñ–∞–∑–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è**: –°–ø–æ—á–∞—Ç–∫—É –º–æ–≤–Ω–∞ –º–æ–¥–µ–ª—å, –ø–æ—Ç—ñ–º —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ–π–Ω–∞
- **CPU-–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–æ**: –ü—Ä–∞—Ü—é—î –Ω–∞ –∑–≤–∏—á–∞–π–Ω–∏—Ö –∫–æ–º–ø'—é—Ç–µ—Ä–∞—Ö –±–µ–∑ GPU
- **Google Colab Ready**: –ü–æ–≤–Ω–∞ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –∑ Google Colab notebook
- **–ë–µ–∑–ø–µ—á–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è**: Gradient clipping, loss guard, sanity checks
- **–Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π —á–∞—Ç**: –ì–æ—Ç–æ–≤–∏–π —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç—É

```
AI-27.12.2025-20_00/
‚îú‚îÄ‚îÄ README.md                    # –¶–µ–π —Ñ–∞–π–ª
‚îú‚îÄ‚îÄ requirements.txt             # –ó–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ Python
‚îú‚îÄ‚îÄ .gitignore                 # –í–∏–∫–ª—é—á–µ–Ω–Ω—è Git
‚îú‚îÄ‚îÄ colab_setup.ipynb          # üÜï Google Colab notebook
‚îú‚îÄ‚îÄ GOOGLE_COLAB_GUIDE.md      # üÜï –Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è –¥–ª—è Colab
‚îú‚îÄ‚îÄ GITHUB_SETUP.md           # üÜï –ì—ñ–¥ –ø–æ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—é GitHub
‚îú‚îÄ‚îÄ config/                   # –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
‚îÇ   ‚îú‚îÄ‚îÄ phase1_pretraining.yaml
‚îÇ   ‚îú‚îÄ‚îÄ phase2_instruction_tuning.yaml
‚îÇ   ‚îî‚îÄ‚îÄ colab_phase2.yaml     # üÜï –û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–æ –¥–ª—è Colab
‚îú‚îÄ‚îÄ scripts/                  # –°–∫—Ä–∏–ø—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è —Ç–∞ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
‚îÇ   ‚îú‚îÄ‚îÄ train_phase1_pretraining.py    # Phase 1: Language Pretraining
‚îÇ   ‚îú‚îÄ‚îÄ train_phase2_instruction_tuning.py  # Phase 2: Instruction Tuning
‚îÇ   ‚îú‚îÄ‚îÄ test_model.py                 # –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
‚îÇ   ‚îú‚îÄ‚îÄ chat.py                      # –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π —á–∞—Ç
‚îÇ   ‚îî‚îÄ‚îÄ check_training_status.py      # –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —Å—Ç–∞—Ç—É—Å—É
‚îú‚îÄ‚îÄ datasets/                 # –î–∞—Ç–∞—Å–µ—Ç–∏
‚îÇ   ‚îú‚îÄ‚îÄ alpaca.json
‚îÇ   ‚îú‚îÄ‚îÄ squad.json
‚îÇ   ‚îî‚îÄ‚îÄ dailydialog_minimal.json
‚îú‚îÄ‚îÄ checkpoints/              # –ú–æ–¥–µ–ª—ñ (–∑ gitignore)
‚îú‚îÄ‚îÄ logs/                    # –õ–æ–≥–∏ (–∑ gitignore)
‚îî‚îÄ‚îÄ core/                    # –û—Å–Ω–æ–≤–Ω—ñ –º–æ–¥—É–ª—ñ
```

---

## üöÄ –®–≤–∏–¥–∫–∏–π —Å—Ç–∞—Ä—Ç

### –õ–æ–∫–∞–ª—å–Ω–∞ –º–∞—à–∏–Ω–∞

1. **–ö–ª–æ–Ω—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ–π**
   ```bash
   git clone https://github.com/your-username/your-repo.git
   cd your-repo
   ```

2. **–ù–∞–ª–∞—à—Ç—É–π—Ç–µ –≤—ñ—Ä—Ç—É–∞–ª—å–Ω–µ —Å–µ—Ä–µ–¥–æ–≤–∏—â–µ**
   ```bash
   # Linux/Mac
   chmod +x setup_venv.sh
   ./setup_venv.sh
   source venv-linux/bin/activate
   
   # Windows
   setup_venv.bat
   venv\Scripts\activate
   ```

3. **–ó–∞–ø—É—Å—Ç—ñ—Ç—å Phase 1 (Language Pretraining)**
   ```bash
   python scripts/train_phase1_pretraining.py \
     --config config/phase1_pretraining.yaml
   ```

4. **–ó–∞–ø—É—Å—Ç—ñ—Ç—å Phase 2 (Instruction Tuning)**
   ```bash
   python scripts/train_phase2_instruction_tuning.py \
     --config config/phase2_instruction_tuning.yaml \
     --phase1-model checkpoints/phase1/best_model.pt
   ```

5. **–ü—Ä–æ—Ç–µ—Å—Ç—É–π—Ç–µ –º–æ–¥–µ–ª—å**
   ```bash
   python scripts/test_model.py \
     --model checkpoints/phase2/best_instruction_model.pt \
     --prompt "What is 2+2?"
   ```

### Google Colab (üÜï)

1. **–í—ñ–¥–∫—Ä–∏–π—Ç–µ –≤ Colab**: [colab_setup.ipynb](colab_setup.ipynb)
2. **–í–∏–∫–æ–Ω—É–π—Ç–µ –∫–ª—ñ—Ç–∏–Ω–∫–∏** –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ
3. **–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è** –Ω–∞ Google Drive

–î–µ—Ç–∞–ª—å–Ω–∞ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è: [GOOGLE_COLAB_GUIDE.md](GOOGLE_COLAB_GUIDE.md)

---

## üìã –í–∏–º–æ–≥–∏

- Python 3.8+
- PyTorch 2.9.1+
- Transformers 4.57.3+
- 8GB+ RAM –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è
- CPU (GPU –æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)

---

## üîß –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è

### Phase 1: Language Pretraining
```yaml
model:
  n_embd: 320
  n_layer: 6
  n_head: 8
  n_positions: 256

training:
  batch_size: 4
  epochs: 3
  learning_rate: 1e-4
```

### Phase 2: Instruction Tuning
```yaml
training:
  batch_size: 4
  epochs: 1
  learning_rate: 5e-5
  gradient_accumulation_steps: 8
  max_grad_norm: 1.0
```

---

## üéÆ –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è

### –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
```bash
python scripts/test_model.py \
  --model checkpoints/phase2/best_instruction_model.pt \
  --prompt "Your question here" \
  --max-tokens 50
```

### –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π —á–∞—Ç
```bash
python scripts/chat.py \
  --model checkpoints/phase2/best_instruction_model.pt \
  --max-tokens 100
```

### –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –Ω–∞–≤—á–∞–Ω–Ω—è
```bash
python scripts/check_training_status.py
```

---

## üìä –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞

### Phase 1: Language Pretraining
- **–ú–æ–¥–µ–ª—å**: GPT-2 –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ (HuggingFace)
- **–ú–µ—Ç–∞**: –ù–∞–≤—á–∏—Ç–∏ –±–∞–∑–æ–≤—É –º–æ–≤–Ω—É –º–æ–¥–µ–ª—å
- **–î–∞—Ç–∞—Å–µ—Ç–∏**: –í—ñ–¥–∫—Ä–∏—Ç—ñ —Ç–µ–∫—Å—Ç–æ–≤—ñ –∫–æ—Ä–ø—É—Å–∏
- **–†–µ–∑—É–ª—å—Ç–∞—Ç**: `checkpoints/phase1/best_model.pt`

### Phase 2: Instruction Tuning
- **–ú–æ–¥–µ–ª—å**: Fine-tuning Phase 1 –º–æ–¥–µ–ª—ñ
- **–ú–µ—Ç–∞**: –ù–∞–≤—á–∏—Ç–∏ –≤–∏–∫–æ–Ω—É–≤–∞—Ç–∏ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó
- **–î–∞—Ç–∞—Å–µ—Ç–∏**: Alpaca, SQuAD, DailyDialog
- **–†–µ–∑—É–ª—å—Ç–∞—Ç**: `checkpoints/phase2/best_instruction_model.pt`

### –ö–ª—é—á–æ–≤—ñ —Ç–µ—Ö–Ω—ñ–∫–∏
- **Gradient Clipping**: –ó–∞–ø–æ–±—ñ–≥–∞–Ω–Ω—è –≤–∏–±—É—Ö—É –≥—Ä–∞–¥—ñ—î–Ω—Ç—ñ–≤
- **Label Masking**: –¢—ñ–ª—å–∫–∏ response —Ç–æ–∫–µ–Ω–∏ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è
- **Loss Guard**: EMA –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –¥–ª—è —Ä–∞–Ω–Ω—å–æ–≥–æ –≤–∏—è–≤–ª–µ–Ω–Ω—è –ø—Ä–æ–±–ª–µ–º
- **Sanity Checks**: –ü–µ—Ä—ñ–æ–¥–∏—á–Ω–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ —è–∫–æ—Å—Ç—ñ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó

---

## üõ†Ô∏è –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –¥–ª—è Google Colab

### –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
- **Batch Size**: 2 (–∑–∞–º—ñ—Å—Ç—å 4)
- **Gradient Accumulation**: 4 (–µ—Ñ–µ–∫—Ç–∏–≤–Ω–∏–π batch = 8)
- **CPU Threads**: 2 (–æ–±–º–µ–∂–µ–Ω–Ω—è Colab)
- **Checkpoint Interval**: 50 (—á–∞—Å—Ç—ñ—à–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è)

### –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü—ñ—è
- **Google Drive Backup**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
- **Resource Monitoring**: –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ CPU/RAM
- **Session Recovery**: –í—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è –ø—ñ—Å–ª—è –ø–µ—Ä–µ—Ä–∏–≤–∞–Ω–Ω—è

---

## üîç Troubleshooting

### –ü—Ä–æ–±–ª–µ–º–∞: Out of Memory
```yaml
# –ó–º–µ–Ω—à—Ç–µ –≤ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
training:
  batch_size: 2
  gradient_accumulation_steps: 8
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ü–æ–≤—ñ–ª—å–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è
```yaml
# –ó–º–µ–Ω—à—Ç–µ —á–∞—Å—Ç–æ—Ç—É –ª–æ–≥—É–≤–∞–Ω–Ω—è
training:
  monitoring_interval: 50
  checkpoint_interval: 100
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ü–æ–≥–∞–Ω–∞ —è–∫—ñ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó
- –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ learning rate (–∑–∞–Ω–∞–¥—Ç–æ –≤–∏—Å–æ–∫–∏–π)
- –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ label masking (–º–æ–∂–µ –±—É—Ç–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∏–º)
- –ó–∞–ø—É—Å—Ç—ñ—Ç—å sanity checks –¥–ª—è –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏

---

## üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è

- [GOOGLE_COLAB_GUIDE.md](GOOGLE_COLAB_GUIDE.md) - –ü–æ–≤–Ω–∞ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è –¥–ª—è Colab
- [GITHUB_SETUP.md](GITHUB_SETUP.md) - –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ—é
- [TWO_PHASE_TRAINING_README.md](TWO_PHASE_TRAINING_README.md) - –î–µ—Ç–∞–ª—å–Ω–∞ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞

---

## ü§ù Contributing

1. Fork —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ–π
2. –°—Ç–≤–æ—Ä—ñ—Ç—å feature branch
3. –ó—Ä–æ–±—ñ—Ç—å changes
4. –°—Ç–≤–æ—Ä—ñ—Ç—å Pull Request

---

## üìÑ –õ—ñ—Ü–µ–Ω–∑—ñ—è

–¶–µ–π –ø—Ä–æ–µ–∫—Ç –ª—ñ—Ü–µ–Ω–∑–æ–≤–∞–Ω–æ –ø—ñ–¥ MIT License - –¥–∏–≤—ñ—Ç—å—Å—è [LICENSE](LICENSE) —Ñ–∞–π–ª.

---

## üôè –ü–æ–¥—è–∫–∏

- HuggingFace –∑–∞ transformers –±—ñ–±–ª—ñ–æ—Ç–µ–∫—É
- OpenAI –∑–∞ GPT-2 –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä—É
- Stanford Alpaca –ø—Ä–æ–µ–∫—Ç –∑–∞ –¥–∞—Ç–∞—Å–µ—Ç
- –°–ø—ñ–ª—å–Ω–æ—Ç—ñ –∑–∞ –≤—ñ–¥–≥—É–∫–∏ —Ç–∞ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è

---

## üìû –ü—ñ–¥—Ç—Ä–∏–º–∫–∞

- **Issues**: [GitHub Issues](https://github.com/your-username/your-repo/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-username/your-repo/discussions)
- **Email**: your-email@example.com

---

**üöÄ –ì–æ—Ç–æ–≤–æ –¥–æ –Ω–∞–≤—á–∞–Ω–Ω—è –≤–∞—à–æ—ó GPT-2 –º–æ–¥–µ–ª—ñ!**

**Windows (Command Prompt):**
```cmd
setup_venv.bat
```

**Windows (PowerShell):**
```powershell
.\setup_venv.ps1
```

**–ê–±–æ –≤—Ä—É—á–Ω—É:**
```bash
# Linux/Mac
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Windows
python -m venv venv
venv\Scripts\activate.bat
pip install -r requirements.txt
```

### –ê–∫—Ç–∏–≤–∞—Ü—ñ—è –≤—ñ—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞

**Linux/Mac:**
```bash
source venv/bin/activate
```

**Windows:**
```cmd
venv\Scripts\activate.bat
```

**Windows (PowerShell):**
```powershell
.\venv\Scripts\Activate.ps1
```

> **–ü—Ä–∏–º—ñ—Ç–∫–∞ –¥–ª—è PowerShell:** –Ø–∫—â–æ –æ—Ç—Ä–∏–º—É—î—Ç–µ –ø–æ–º–∏–ª–∫—É "execution of scripts is disabled", –≤–∏–∫–æ–Ω–∞–π—Ç–µ:
> ```powershell
> Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
> ```

### –û–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω—ñ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ

–î–ª—è —Ä–æ–±–æ—Ç–∏ –∑ GGUF –º–æ–¥–µ–ª—è–º–∏ (Phi-3, —Ç–æ—â–æ):
```bash
pip install llama-cpp-python
```

–ê–±–æ —Ä–æ–∑–∫–æ–º–µ–Ω—Ç—É–π—Ç–µ —Ä—è–¥–æ–∫ –≤ `requirements.txt`:
```txt
llama-cpp-python  # –†–æ–∑–∫–æ–º–µ–Ω—Ç—É–π—Ç–µ —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
```

---

## üéØ –®–≤–∏–¥–∫–∏–π —Å—Ç–∞—Ä—Ç

### 1. –ó–∞–ø—É—Å–∫ –Ω–∞–≤—á–∞–Ω–Ω—è

**–û—Å–Ω–æ–≤–Ω–∏–π —Å–ø–æ—Å—ñ–±:**
```bash
./start_training.sh
```

**–ê–±–æ –Ω–∞–ø—Ä—è–º—É:**
```bash
cd /media/sony/641bf160-e2a6-47a2-b335-1da24af98536/ai/tiny_recursive_model-0.0.12
source venv/bin/activate

python scripts/train_model.py \
    --dataset datasets/train/openassistant_train.json \
    --dim 1024 \
    --seq-len 4096 \
    --batch-size 1 \
    --epochs 15 \
    --learning-rate 2e-4 \
    --checkpoint-dir checkpoints \
    --checkpoint-interval 100
```

### 2. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å—É –Ω–∞–≤—á–∞–Ω–Ω—è

```bash
python scripts/check_training_status.py
```

**–ê–±–æ —á–µ—Ä–µ–∑ —Å–∫—Ä–∏–ø—Ç:**
```bash
./check_training.sh
```

### 3. –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥

**–ü—Ä–æ—Å—Ç–∏–π –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥:**
```bash
./monitor.sh
```

**–î–µ—Ç–∞–ª—å–Ω–∏–π –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –∑ –≤–∏—è–≤–ª–µ–Ω–Ω—è–º –ø—Ä–æ–±–ª–µ–º:**
```bash
./monitor_training.sh
```

–î–µ—Ç–∞–ª—å–Ω–∏–π –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ:
- –í–∏—è–≤–ª—è—î –ø—ñ–¥–≤–∏—Å–∞–Ω–Ω—è (—è–∫—â–æ –ª–æ–≥ –Ω–µ –æ–Ω–æ–≤–ª—é—î—Ç—å—Å—è > 5 —Ö–≤)
- –í–∏—è–≤–ª—è—î –æ–±–º–µ–∂–µ–Ω–Ω—è —Ä–µ—Å—É—Ä—Å—ñ–≤ (–≤–∏—Å–æ–∫–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è CPU/–ø–∞–º'—è—Ç—ñ)
- –õ–æ–≥—É—î –≤—Å—ñ –≤–∏—è–≤–ª–µ–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏ –≤ `logs/monitoring_*.log`

### 4. –ó—É–ø–∏–Ω–∫–∞ –Ω–∞–≤—á–∞–Ω–Ω—è

```bash
./stop_training.sh
```

---

## üìä –î–µ —â–æ –∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è

### üöÄ –ó–∞–ø—É—Å–∫ –Ω–∞–≤—á–∞–Ω–Ω—è

| –§–∞–π–ª | –û–ø–∏—Å |
|------|------|
| `start_training.sh` | **–ì–æ–ª–æ–≤–Ω–∏–π —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫—É** - –∑–∞–ø—É—Å–∫–∞—î –Ω–∞–≤—á–∞–Ω–Ω—è –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ |
| `scripts/train_model.py` | **–û—Å–Ω–æ–≤–Ω–∏–π Python —Å–∫—Ä–∏–ø—Ç** - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î `train_with_auto_config()` |
| `train/train_code_model.py` | –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∏–π —Å–∫—Ä–∏–ø—Ç –Ω–∞–≤—á–∞–Ω–Ω—è (–¥–ª—è –∫–æ–¥—É) |

### üß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è

| –§–∞–π–ª | –û–ø–∏—Å |
|------|------|
| `scripts/test_model.py` | –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –Ω–∞–≤—á–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ |
| `scripts/test_model_capabilities.py` | –†–æ–∑—à–∏—Ä–µ–Ω–µ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è –º–æ–∂–ª–∏–≤–æ—Å—Ç–µ–π |

### üìà –°—Ç–∞—Ç—É—Å —Ç–∞ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥

| –§–∞–π–ª | –û–ø–∏—Å |
|------|------|
| `scripts/check_training_status.py` | **–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å—É** - –ø–æ–∫–∞–∑—É—î —á–∏ –ø—Ä–∞—Ü—é—î –Ω–∞–≤—á–∞–Ω–Ω—è, –ø—Ä–æ–≥—Ä–µ—Å, checkpoint'–∏ |
| `check_training.sh` | Shell —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å—É |
| `monitor.sh` | –ü—Ä–æ—Å—Ç–∏–π –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ—Ü–µ—Å—É –Ω–∞–≤—á–∞–Ω–Ω—è |
| `monitor_training.sh` | –î–µ—Ç–∞–ª—å–Ω–∏–π –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –∑ –≤–∏—è–≤–ª–µ–Ω–Ω—è–º –ø—ñ–¥–≤–∏—Å–∞–Ω—å —Ç–∞ –æ–±–º–µ–∂–µ–Ω—å —Ä–µ—Å—É—Ä—Å—ñ–≤ |

### üíæ Checkpoint'–∏ —Ç–∞ –º–æ–¥–µ–ª—ñ

| –ü–∞–ø–∫–∞/–§–∞–π–ª | –û–ø–∏—Å |
|------------|------|
| `checkpoints/` | –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —Å—Ç–≤–æ—Ä—é—î—Ç—å—Å—è, –º—ñ—Å—Ç–∏—Ç—å checkpoint'–∏ –Ω–∞–≤—á–∞–Ω–Ω—è |
| `checkpoints/checkpoint_latest.pt` | –û—Å—Ç–∞–Ω–Ω—ñ–π checkpoint –¥–ª—è –ø—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è |
| `models/trained/` | –ù–∞–≤—á–µ–Ω—ñ –º–æ–¥–µ–ª—ñ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è —Ç—É—Ç |

---

## üîß –û—Å–Ω–æ–≤–Ω—ñ –∫–æ–º–∞–Ω–¥–∏

### –ù–∞–≤—á–∞–Ω–Ω—è

```bash
# –ó–∞–ø—É—Å–∫ –Ω–∞–≤—á–∞–Ω–Ω—è
./start_training.sh

# –ê–±–æ –Ω–∞–ø—Ä—è–º—É
python scripts/train_model.py --dataset datasets/train/openassistant_train.json
```

### –ü—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è –ø—ñ—Å–ª—è –ø–µ—Ä–µ—Ä–≤–∏

```bash
python scripts/train_model.py \
    --dataset datasets/train/openassistant_train.json \
    --resume checkpoints/checkpoint_latest.pt \
    --checkpoint-dir checkpoints
```

**–ê–±–æ —á–µ—Ä–µ–∑ —Å–∫—Ä–∏–ø—Ç:**
```bash
./start_training.sh
# –°–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –∑–∞–ø—Ä–æ–ø–æ–Ω—É—î –ø—Ä–æ–¥–æ–≤–∂–∏—Ç–∏ –∑ checkpoint'—É —è–∫—â–æ –≤—ñ–Ω —î
```

### –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å—É

```bash
# Python —Å–∫—Ä–∏–ø—Ç (–¥–µ—Ç–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è)
python scripts/check_training_status.py

# Shell —Å–∫—Ä–∏–ø—Ç (—à–≤–∏–¥–∫–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞)
./check_training.sh

# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—Ä–æ—Ü–µ—Å—ñ–≤
ps aux | grep train_model
```

### –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥

```bash
# –ü—Ä–æ—Å—Ç–∏–π –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ (—à–≤–∏–¥–∫–∏–π –ø–µ—Ä–µ–≥–ª—è–¥)
./monitor.sh

# –î–µ—Ç–∞–ª—å–Ω–∏–π –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ (–≤–∏—è–≤–ª–µ–Ω–Ω—è –ø—Ä–æ–±–ª–µ–º, –ª–æ–≥—É–≤–∞–Ω–Ω—è)
./monitor_training.sh

# –ê–±–æ Python —Å–∫—Ä–∏–ø—Ç (–¥–µ—Ç–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è)
python scripts/check_training_status.py
```

### –ó—É–ø–∏–Ω–∫–∞

```bash
./stop_training.sh
```

### –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ –¥–ª—è –¥–æ–Ω–∞–≤—á–∞–Ω–Ω—è

```bash
# –ó–±–µ—Ä–µ–≥—Ç–∏ –º–æ–¥–µ–ª—å –∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–º –ø–æ—à—É–∫–æ–º –æ—Å—Ç–∞–Ω–Ω—å–æ—ó –º–æ–¥–µ–ª—ñ —Ç–∞ —á–µ–∫–ø–æ—ñ–Ω—Ç—ñ–≤
python scripts/save_model.py --model-name my_model --dataset-path datasets/train/openassistant_train.json

# –ó–±–µ—Ä–µ–≥—Ç–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É –º–æ–¥–µ–ª—å
python scripts/save_model.py --model-name my_model --model-path models/trained/model.pt --checkpoint-dir checkpoints --dataset-path datasets/train/openassistant_train.json
```

–°–∫—Ä–∏–ø—Ç —Å—Ç–≤–æ—Ä–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤ `saved_models/{model_name}/` –∑:
- –ú–æ–¥–µ–ª–ª—é (`model.pt`)
- –í—Å—ñ–º–∞ —á–µ–∫–ø–æ—ñ–Ω—Ç–∞–º–∏ (`checkpoints/`)
- –î–∞—Ç–∞—Å–µ—Ç–æ–º (`dataset/`)
- –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—î—é (`model_config.json`, `training_config.json`)
- –Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è–º–∏ –¥–ª—è –¥–æ–Ω–∞–≤—á–∞–Ω–Ω—è (`README.md`)

---

## üìù –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –Ω–∞–≤—á–∞–Ω–Ω—è

### –ü–æ—Ç–æ—á–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ (–≤ `start_training.sh`):

- **–î–∞—Ç–∞—Å–µ—Ç:** `datasets/train/openassistant_train.json`
- **dim:** 1024
- **seq_len:** 4096
- **batch_size:** 1
- **epochs:** 15
- **learning_rate:** 2e-4
- **checkpoint_interval:** 100 (–∑–±–µ—Ä—ñ–≥–∞—î –∫–æ–∂–Ω—ñ 100 –±–∞—Ç—á—ñ–≤)

### –ó–º—ñ–Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤

–í—ñ–¥—Ä–µ–¥–∞–≥—É–π—Ç–µ `start_training.sh` –∞–±–æ –∑–∞–ø—É—Å–∫–∞–π—Ç–µ –Ω–∞–ø—Ä—è–º—É:

```bash
python scripts/train_model.py \
    --dataset datasets/train/openassistant_train.json \
    --dim 512 \
    --seq-len 2048 \
    --batch-size 4 \
    --epochs 20 \
    --learning-rate 1e-4
```

---

## üî¨ –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π (GGUF —Ç–∞ TRM)

–°–∫—Ä–∏–ø—Ç `scripts/compare_gguf_models.py` –¥–æ–∑–≤–æ–ª—è—î –ø–æ—Ä—ñ–≤–Ω—é–≤–∞—Ç–∏:
- **GGUF –º–æ–¥–µ–ª—ñ** (Phi-3, TinyLlama, DeepSeek —Ç–æ—â–æ)
- **–ù–∞–≤—á–µ–Ω—ñ TRM –º–æ–¥–µ–ª—ñ** (–≤–∞—à—ñ –∫–∞—Å—Ç–æ–º–Ω—ñ –º–æ–¥–µ–ª—ñ)
- **–ó–º—ñ—à–∞–Ω—ñ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è** (GGUF –∑ TRM)

### –û—Å–Ω–æ–≤–Ω—ñ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ:

1. **–í–∏–±—ñ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π** - –≤–∏ –º–æ–∂–µ—Ç–µ –≤–∫–∞–∑–∞—Ç–∏ —è–∫—ñ —Å–∞–º–µ –º–æ–¥–µ–ª—ñ –ø–æ—Ä—ñ–≤–Ω—é–≤–∞—Ç–∏
2. **–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è GGUF –∑ TRM** - –ø–æ—Ä—ñ–≤–Ω—è–π—Ç–µ —Å–≤–æ—é –Ω–∞–≤—á–µ–Ω—É –º–æ–¥–µ–ª—å –∑ GGUF –º–æ–¥–µ–ª—è–º–∏
3. **–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ç–∏–ø—É** - —Å–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞—î —Ç–∏–ø –º–æ–¥–µ–ª—ñ

### –ü—Ä–∏–∫–ª–∞–¥–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:

**–ü–æ—Ä—ñ–≤–Ω—è—Ç–∏ –≤—Å—ñ –∑–Ω–∞–π–¥–µ–Ω—ñ GGUF –º–æ–¥–µ–ª—ñ:**

```bash
python scripts/compare_gguf_models.py --all
```

**–ü–æ—Ä—ñ–≤–Ω—è—Ç–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ GGUF –º–æ–¥–µ–ª—ñ:**

```bash
python scripts/compare_gguf_models.py \
    --models models/gguf/phi-3.5-mini-instruct-q4_k_m.gguf \
              models/gguf/tinyllama-1.1b-chat-v1.0.Q5_K_M.gguf
```

**–ü–æ—Ä—ñ–≤–Ω—è—Ç–∏ TRM –º–æ–¥–µ–ª—å –∑ GGUF –º–æ–¥–µ–ª—è–º–∏:**

```bash
# –ü–æ—Ä—ñ–≤–Ω—è—Ç–∏ –≤–∞—à—É –Ω–∞–≤—á–µ–Ω—É TRM –º–æ–¥–µ–ª—å –∑ GGUF –º–æ–¥–µ–ª—è–º–∏
python scripts/compare_gguf_models.py \
    --models models/trained/my_model.pt \
              models/gguf/phi-3.5-mini-instruct-q4_k_m.gguf \
    --trm-config models/trained/my_model_config.json
```

**–ü–æ—Ä—ñ–≤–Ω—è—Ç–∏ —Ç—ñ–ª—å–∫–∏ TRM –º–æ–¥–µ–ª—ñ:**

```bash
# –ü–æ—Ä—ñ–≤–Ω—è—Ç–∏ –≤—Å—ñ –∑–Ω–∞–π–¥–µ–Ω—ñ TRM –º–æ–¥–µ–ª—ñ
python scripts/compare_gguf_models.py --all-trm

# –ê–±–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ TRM –º–æ–¥–µ–ª—ñ
python scripts/compare_gguf_models.py \
    --trm-models models/trained/model1.pt \
                 models/trained/model2.pt
```

**–ó–º—ñ—à–∞–Ω–µ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è (GGUF + TRM):**

```bash
# –°–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏–∑–Ω–∞—á–∏—Ç—å —Ç–∏–ø –∫–æ–∂–Ω–æ—ó –º–æ–¥–µ–ª—ñ
python scripts/compare_gguf_models.py \
    --models models/gguf/phi-3.5-mini-instruct-q4_k_m.gguf \
              models/trained/my_model.pt \
              models/gguf/tinyllama-1.1b-chat-v1.0.Q5_K_M.gguf
```

### –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è:

–°–∫—Ä–∏–ø—Ç –ø–æ—Ä—ñ–≤–Ω—é—î:
- ‚ö° **–®–≤–∏–¥–∫—ñ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó** (—Ç–æ–∫–µ–Ω—ñ–≤/—Å–µ–∫)
- üéØ **–Ø–∫—ñ—Å—Ç—å –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π** (–≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å –æ—á—ñ–∫—É–≤–∞–Ω–∏–º –∫–ª—é—á–æ–≤–∏–º —Å–ª–æ–≤–∞–º)
- ‚úÖ **–ù–∞–¥—ñ–π–Ω—ñ—Å—Ç—å** (—É—Å–ø—ñ—à–Ω—ñ—Å—Ç—å —Ç–µ—Å—Ç—ñ–≤)
- üîÑ **–ö—Ä–æ–∫–∏ —É—Ç–æ—á–Ω–µ–Ω–Ω—è** (–¥–ª—è TRM –º–æ–¥–µ–ª–µ–π)

–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è –≤ JSON –∑–≤—ñ—Ç—ñ –∑ –¥–µ—Ç–∞–ª—å–Ω–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –¥–ª—è –∫–æ–∂–Ω–æ—ó –º–æ–¥–µ–ª—ñ.

---

## üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è

–í—Å—ñ –¥–µ—Ç–∞–ª—å–Ω—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏ –ø—Ä–æ–µ–∫—Ç—É –∑–Ω–∞—Ö–æ–¥—è—Ç—å—Å—è –≤ –ø–∞–ø—Ü—ñ [`README/`](README/README.md):

- [–ê—É–¥–∏—Ç –ø—Ä–æ–µ–∫—Ç—É](README/AUDIT_REPORT.md)
- [–ö–µ—Ä—ñ–≤–Ω–∏—Ü—Ç–≤–æ –∑ checkpoint'—ñ–≤](README/CHECKPOINT_GUIDE.md)
- [–ü—ñ–¥—Å—É–º–æ–∫ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥—É](README/REFACTORING_SUMMARY.md)
- [–ê—É–¥–∏—Ç —Å–∫—Ä–∏–ø—Ç—ñ–≤](README/SCRIPTS_AUDIT_REPORT.md)
- [–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤](README/PARAMETERS_CHECK.md)

---

## ‚ö†Ô∏è –í–∞–∂–ª–∏–≤–æ

1. **–í—ñ—Ä—Ç—É–∞–ª—å–Ω–µ —Å–µ—Ä–µ–¥–æ–≤–∏—â–µ:** –ó–∞–≤–∂–¥–∏ –∞–∫—Ç–∏–≤—É–π—Ç–µ `venv` –ø–µ—Ä–µ–¥ —Ä–æ–±–æ—Ç–æ—é:
   ```bash
   source venv/bin/activate
   ```

2. **Checkpoint'–∏:** –ù–∞–≤—á–∞–Ω–Ω—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –∑–±–µ—Ä—ñ–≥–∞—î checkpoint'–∏ –≤ `checkpoints/`. –ú–æ–∂–Ω–∞ –ø—Ä–æ–¥–æ–≤–∂–∏—Ç–∏ –ø—ñ—Å–ª—è –ø–µ—Ä–µ—Ä–≤–∏.

3. **–ú–æ–¥–µ–ª—ñ:** –ù–∞–≤—á–µ–Ω—ñ –º–æ–¥–µ–ª—ñ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è –≤ `models/trained/`

4. **–î–∞—Ç–∞—Å–µ—Ç–∏:** –î–∞—Ç–∞—Å–µ—Ç–∏ –∑–Ω–∞—Ö–æ–¥—è—Ç—å—Å—è –≤ `datasets/train/` —Ç–∞ `datasets/eval/`

---

## üìù –õ–æ–≥—É–≤–∞–Ω–Ω—è —Ç–∞ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ª–æ–≥—ñ–≤

–í—Å—ñ –ª–æ–≥–∏ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è –≤ –ø–∞–ø—Ü—ñ `logs/`:

- **`logs/training_*.log`** - –æ—Å–Ω–æ–≤–Ω—ñ –ª–æ–≥–∏ –Ω–∞–≤—á–∞–Ω–Ω—è (–∑ timestamp)
- **`logs/training_latest.log`** - —Å–∏–º–≤–æ–ª—ñ—á–Ω–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –æ—Å—Ç–∞–Ω–Ω—ñ–π –ª–æ–≥
- **`logs/training_detailed_*.log`** - –¥–µ—Ç–∞–ª—å–Ω—ñ –ª–æ–≥–∏ –∑ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—î—é –ø—Ä–æ —Ä–µ—Å—É—Ä—Å–∏
- **`logs/resource_monitor_*.log`** - –ª–æ–≥–∏ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É —Ä–µ—Å—É—Ä—Å—ñ–≤ (CPU, –ø–∞–º'—è—Ç—å, GPU)
- **`logs/monitoring_*.log`** - –ª–æ–≥–∏ –∑ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥–æ–≤–∏—Ö —Å–∫—Ä–∏–ø—Ç—ñ–≤
- **`logs/*.json`** - –º–µ—Ç—Ä–∏–∫–∏ —Ç–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤ JSON —Ñ–æ—Ä–º–∞—Ç—ñ

### –ü–µ—Ä–µ–≥–ª—è–¥ –ª–æ–≥—ñ–≤

```bash
# –û—Å—Ç–∞–Ω–Ω—ñ–π –ª–æ–≥ –Ω–∞–≤—á–∞–Ω–Ω—è
tail -f logs/training_latest.log

# –î–µ—Ç–∞–ª—å–Ω–∏–π –ª–æ–≥ –∑ —Ä–µ—Å—É—Ä—Å–∞–º–∏
tail -f logs/training_detailed_*.log

# –õ–æ–≥ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É —Ä–µ—Å—É—Ä—Å—ñ–≤
tail -f logs/resource_monitor_*.log

# –õ–æ–≥ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥–æ–≤–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞
tail -f logs/monitoring_*.log
```

### –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å—ñ–≤

–ü—ñ–¥ —á–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤—ñ–¥—Å—Ç–µ–∂—É—é—Ç—å—Å—è:
- **CPU –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è** - –≤–∏—è–≤–ª–µ–Ω–Ω—è –≤–∏—Å–æ–∫–æ–≥–æ –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è (>95%)
- **–ü–∞–º'—è—Ç—å (RAM)** - –≤–∏—è–≤–ª–µ–Ω–Ω—è –≤–∏—Å–æ–∫–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è (>90%)
- **GPU –ø–∞–º'—è—Ç—å** - —è–∫—â–æ GPU –¥–æ—Å—Ç—É–ø–Ω–∏–π
- **–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –±–∞—Ç—á—ñ–≤** - –≤–∏—è–≤–ª–µ–Ω–Ω—è –ø–æ–≤—ñ–ª—å–Ω–∏—Ö –±–∞—Ç—á—ñ–≤ (>60 —Å–µ–∫—É–Ω–¥)
- **–ü—ñ–¥–≤–∏—Å–∞–Ω–Ω—è** - –≤–∏—è–≤–ª–µ–Ω–Ω—è –∑–∞–≤–∏—Å–ª–∏—Ö –ø—Ä–æ—Ü–µ—Å—ñ–≤

–í—Å—ñ –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –ª–æ–≥—É—é—Ç—å—Å—è –≤ `logs/resource_monitor_*.log`.

### –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è

```bash
# –ó–º—ñ–Ω–∏—Ç–∏ —ñ–Ω—Ç–µ—Ä–≤–∞–ª –ª–æ–≥—É–≤–∞–Ω–Ω—è —Ä–µ—Å—É—Ä—Å—ñ–≤ (–∫–æ–∂–Ω—ñ N –±–∞—Ç—á—ñ–≤)
python scripts/train_model.py --log-interval 20

# –í–∏–º–∫–Ω—É—Ç–∏ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å—ñ–≤
python scripts/train_model.py --disable-resource-monitor

# –í–∏–º–∫–Ω—É—Ç–∏ –ª–æ–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∫—É—Ä—Å—ñ—ó
python scripts/train_model.py --disable-recursion-logging
```

## üÜò –î–æ–ø–æ–º–æ–≥–∞

–Ø–∫—â–æ —â–æ—Å—å –Ω–µ –ø—Ä–∞—Ü—é—î:

1. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ —á–∏ –∞–∫—Ç–∏–≤–æ–≤–∞–Ω–æ venv: `source venv/bin/activate`
2. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ —Å—Ç–∞—Ç—É—Å: `python scripts/check_training_status.py`
3. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –ø—Ä–æ—Ü–µ—Å–∏: `ps aux | grep train_model`
4. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –ª–æ–≥–∏: `tail -f logs/training_latest.log`
5. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å—ñ–≤: `tail -f logs/resource_monitor_*.log`

---

**–û—Å—Ç–∞–Ω–Ω—î –æ–Ω–æ–≤–ª–µ–Ω–Ω—è:** 18 –≥—Ä—É–¥–Ω—è 2025
# AI_project

## ‚úÖ GitHub sanity check
Commit from mobile Debian terminal (Pixel 7)

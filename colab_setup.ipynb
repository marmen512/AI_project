{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPT-2 Two-Phase Training in Google Colab\n",
        "\n",
        "–¶–µ–π notebook –¥–æ–∑–≤–æ–ª—è—î –∑–∞–ø—É—Å–∫–∞—Ç–∏ –¥–≤–æ—Ñ–∞–∑–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è GPT-2 –≤ Google Colab.\n",
        "\n",
        "## –í–∞–∂–ª–∏–≤—ñ –æ–±–º–µ–∂–µ–Ω–Ω—è Colab:\n",
        "- CPU-only (–±–µ–∑ GPU –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ–π)\n",
        "- –û–±–º–µ–∂–µ–Ω–∏–π —á–∞—Å —Å–µ—Å—ñ—ó (12 –≥–æ–¥–∏–Ω)\n",
        "- –û–±–º–µ–∂–µ–Ω–µ –¥–∏—Å–∫–æ–≤–µ –ø—Ä–æ—Å—Ç—ñ—Ä\n",
        "- –†–µ–∫–æ–º–µ–Ω–¥—É—î—Ç—å—Å—è —Ç—ñ–ª—å–∫–∏ –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è, –Ω–µ –¥–ª—è –ø–æ–≤–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è PyTorch —Ç–∞ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π –¥–ª—è CPU\n",
        "!pip install torch==2.9.1 transformers==4.57.3 datasets==4.4.2 PyYAML==6.0.3 tqdm==4.67.1 loguru==0.7.3\n",
        "!pip install tokenizers==0.22.1 safetensors==0.7.0\n",
        "\n",
        "print(\"‚úÖ –ó–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. –ö–ª–æ–Ω—É–≤–∞–Ω–Ω—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ—é"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ö–ª–æ–Ω—É–≤–∞–Ω–Ω—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ—é\n",
        "!git clone https://github.com/your-username/your-repo.git AI_project\n",
        "%cd AI_project\n",
        "\n",
        "print(\"‚úÖ –†–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ–π –∫–ª–æ–Ω–æ–≤–∞–Ω–æ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç—ñ–≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç—ñ–≤\n",
        "!mkdir -p datasets\n",
        "\n",
        "# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞—Ç–∞—Å–µ—Ç—ñ–≤ (–ø—Ä–∏–∫–ª–∞–¥–∏)\n",
        "!wget -O datasets/alpaca.json https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/alpaca_data.json\n",
        "\n",
        "# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º—ñ–Ω—ñ–º–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç—É –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è\n",
        "import json\n",
        "minimal_data = {\n",
        "  \"metadata\": {\"name\": \"minimal\"},\n",
        "  \"data\": [\n",
        "    {\n",
        "      \"instruction\": \"What is 2+2?\",\n",
        "      \"input\": \"\",\n",
        "      \"output\": \"4\"\n",
        "    },\n",
        "    {\n",
        "      \"instruction\": \"Name a color.\",\n",
        "      \"input\": \"\",\n",
        "      \"output\": \"Blue\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n",
        "with open('datasets/minimal_test.json', 'w') as f:\n",
        "  json.dump(minimal_data, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ –î–∞—Ç–∞—Å–µ—Ç–∏ –ø—ñ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –¥–ª—è Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –¥–ª—è Colab (CPU-optimized)\n",
        "import yaml\n",
        "\n",
        "colab_config = {\n",
        "  \"model\": {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"n_embd\": 320,\n",
        "    \"n_layer\": 6,\n",
        "    \"n_head\": 8,\n",
        "    \"n_positions\": 256,\n",
        "    \"transformer_cache_dir\": \"models/pretrained\"\n",
        "  },\n",
        "  \"training\": {\n",
        "    \"batch_size\": 2,  # –ú–µ–Ω—à–∏–π batch –¥–ª—è Colab\n",
        "    \"epochs\": 1,\n",
        "    \"learning_rate\": 5e-5,\n",
        "    \"gradient_accumulation_steps\": 4,\n",
        "    \"max_grad_norm\": 1.0,\n",
        "    \"sanity_interval\": 50,\n",
        "    \"optimizer\": \"adamw\",\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"warmup_steps\": 10,\n",
        "    \"checkpoint_dir\": \"checkpoints\",\n",
        "    \"checkpoint_interval\": 100,\n",
        "    \"save_every_steps\": 25,\n",
        "    \"keep_checkpoints\": 3,\n",
        "    \"auto_resume\": False,\n",
        "    \"enable_monitoring\": True,\n",
        "    \"monitoring_interval\": 10,\n",
        "    \"log_dir\": \"logs\",\n",
        "    \"loss_guard_enabled\": True,\n",
        "    \"loss_guard_ema_beta\": 0.98,\n",
        "    \"loss_guard_warmup_steps\": 50,\n",
        "    \"loss_guard_threshold_ratio\": 0.5,\n",
        "    \"loss_guard_patience_steps\": 100\n",
        "  },\n",
        "  \"dataset\": {\n",
        "    \"path\": \"datasets/minimal_test.json\",  # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è\n",
        "    \"type\": \"trm\",\n",
        "    \"format\": \"instruction\",\n",
        "    \"cache_size\": 100,\n",
        "    \"validate_format\": True,\n",
        "    \"tokenizer_name\": \"gpt2\",\n",
        "    \"add_special_tokens\": True\n",
        "  },\n",
        "  \"cpu_optimization\": {\n",
        "    \"num_threads\": 2,  # –û–±–º–µ–∂–µ–Ω–Ω—è –¥–ª—è Colab\n",
        "    \"num_workers\": 0,\n",
        "    \"pin_memory\": False\n",
        "  }\n",
        "}\n",
        "\n",
        "with open('config/colab_phase2.yaml', 'w') as f:\n",
        "  yaml.dump(colab_config, f, default_flow_style=False)\n",
        "\n",
        "print(\"‚úÖ –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é –¥–ª—è Colab —Å—Ç–≤–æ—Ä–µ–Ω–æ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. –ó–∞–ø—É—Å–∫ Phase 1 (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ó–∞–ø—É—Å–∫ Phase 1 (—Ç—ñ–ª—å–∫–∏ –¥–ª—è –ø–æ–≤–Ω–æ–≥–æ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è)\n",
        "# –£–≤—ñ–º–∫–Ω—ñ—Ç—å, —è–∫—â–æ —Ö–æ—á–µ—Ç–µ –ø—Ä–æ–π—Ç–∏ –ø–æ–≤–Ω–∏–π —Ü–∏–∫–ª\n",
        "\n",
        "run_phase1 = False  # –ó–º—ñ–Ω—ñ—Ç—å –Ω–∞ True –¥–ª—è –∑–∞–ø—É—Å–∫—É\n",
        "\n",
        "if run_phase1:\n",
        "  !python scripts/train_phase1_pretraining.py \\\n",
        "    --config config/phase1_pretraining.yaml\n",
        "else:\n",
        "  print(\"‚ÑπÔ∏è Phase 1 –ø—Ä–æ–ø—É—â–µ–Ω–æ (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–æ—á–∞—Ç–∫–æ–≤–æ—ó –º–æ–¥–µ–ª—ñ (—è–∫—â–æ Phase 1 –ø—Ä–æ–ø—É—â–µ–Ω–æ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –±–∞–∑–æ–≤–æ—ó –º–æ–¥–µ–ª—ñ –¥–ª—è Phase 2\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Config\n",
        "import os\n",
        "\n",
        "if not os.path.exists('checkpoints/phase1'):\n",
        "  os.makedirs('checkpoints/phase1', exist_ok=True)\n",
        "  \n",
        "  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó\n",
        "  config = GPT2Config(\n",
        "      vocab_size=50257,\n",
        "      n_embd=320,\n",
        "      n_layer=6,\n",
        "      n_head=8,\n",
        "      n_positions=256\n",
        "  )\n",
        "  \n",
        "  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ\n",
        "  model = GPT2LMHeadModel(config)\n",
        "  \n",
        "  # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è\n",
        "  torch.save(model.state_dict(), 'checkpoints/phase1/best_model.pt')\n",
        "  \n",
        "  print(\"‚úÖ –ë–∞–∑–æ–≤—É –º–æ–¥–µ–ª—å –¥–ª—è Phase 2 —Å—Ç–≤–æ—Ä–µ–Ω–æ\")\n",
        "else:\n",
        "  print(\"‚ÑπÔ∏è –ú–æ–¥–µ–ª—å Phase 1 –≤–∂–µ —ñ—Å–Ω—É—î\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. –ó–∞–ø—É—Å–∫ Phase 2 - Instruction Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ó–∞–ø—É—Å–∫ Phase 2 –∑ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–æ—é –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—î—é\n",
        "!python scripts/train_phase2_instruction_tuning.py \\\n",
        "  --config config/colab_phase2.yaml \\\n",
        "  --phase1-model checkpoints/phase1/best_model.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –Ω–∞–≤—á–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ\n",
        "!python scripts/test_model.py \\\n",
        "  --model checkpoints/phase2/best_instruction_model.pt \\\n",
        "  --prompt \"What is 2+2?\" \\\n",
        "  --max-tokens 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π —á–∞—Ç –∑ –º–æ–¥–µ–ª–ª—é"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ó–∞–ø—É—Å–∫ —ñ–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ —á–∞—Ç—É\n",
        "!python scripts/chat.py \\\n",
        "  --model checkpoints/phase2/best_instruction_model.pt \\\n",
        "  --max-tokens 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å—ñ–≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —Ä–µ—Å—É—Ä—Å—ñ–≤\n",
        "import psutil\n",
        "import time\n",
        "\n",
        "def monitor_resources():\n",
        "    cpu_percent = psutil.cpu_percent()\n",
        "    memory = psutil.virtual_memory()\n",
        "    disk = psutil.disk_usage('/')\n",
        "    \n",
        "    print(f\"üñ•Ô∏è CPU: {cpu_percent}%\")\n",
        "    print(f\"üíæ RAM: {memory.percent}% ({memory.used/1024/1024/1024:.1f}GB/{memory.total/1024/1024/1024:.1f}GB)\")\n",
        "    print(f\"üíø Disk: {disk.percent}% ({disk.used/1024/1024/1024:.1f}GB/{disk.total/1024/1024/1024:.1f}GB)\")\n",
        "\n",
        "# –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –∫–æ–∂–Ω—ñ 30 —Å–µ–∫—É–Ω–¥\n",
        "for i in range(10):\n",
        "    print(f\"\\n--- Check {i+1}/10 ---\")\n",
        "    monitor_resources()\n",
        "    time.sleep(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –Ω–∞ Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è Google Drive —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–∞–ø–∫–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "results_dir = f\"/content/drive/MyDrive/GPT2_Training_{timestamp}\"\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# –ö–æ–ø—ñ—é–≤–∞–Ω–Ω—è –≤–∞–∂–ª–∏–≤–∏—Ö —Ñ–∞–π–ª—ñ–≤\n",
        "files_to_copy = [\n",
        "    'checkpoints/',\n",
        "    'logs/',\n",
        "    'config/colab_phase2.yaml',\n",
        "    'requirements.txt'\n",
        "]\n",
        "\n",
        "for item in files_to_copy:\n",
        "    if os.path.exists(item):\n",
        "        dest = os.path.join(results_dir, os.path.basename(item.rstrip('/')))\n",
        "        if os.path.isdir(item):\n",
        "            shutil.copytree(item, dest, dirs_exist_ok=True)\n",
        "        else:\n",
        "            shutil.copy2(item, dest)\n",
        "        print(f\"‚úÖ –°–∫–æ–ø—ñ–π–æ–≤–∞–Ω–æ: {item} -> {dest}\")\n",
        "\n",
        "print(f\"\\nüéØ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤: {results_dir}\")\n",
        "print(\"üíæ –í–∏ –º–æ–∂–µ—Ç–µ –∑–Ω–∞–π—Ç–∏ –≤—Å—ñ checkpoints —Ç–∞ –ª–æ–≥–∏ —É –≤–∞—à–æ–º—É Google Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –í–∞–∂–ª–∏–≤—ñ –ø–æ—Ä–∞–¥–∏ –¥–ª—è Colab:\n",
        "\n",
        "1. **–ß–∞—Å —Å–µ—Å—ñ—ó**: Colab –æ–±–º–µ–∂—É—î —Å–µ—Å—ñ—ó ~12 –≥–æ–¥–∏–Ω. –ó–±–µ—Ä–µ–∂—É–π—Ç–µ –ø—Ä–æ–≥—Ä–µ—Å.\n",
        "2. **–†–µ—Å—É—Ä—Å–∏**: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –º–µ–Ω—à—ñ batch sizes –¥–ª—è —É–Ω–∏–∫–Ω–µ–Ω–Ω—è –ø–µ—Ä–µ–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è.\n",
        "3. **–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è**: –†–µ–≥—É–ª—è—Ä–Ω–æ –∫–æ–ø—ñ—é–π—Ç–µ checkpoints –Ω–∞ Google Drive.\n",
        "4. **GPU**: –¶–µ–π –∫–æ–¥ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–π –¥–ª—è CPU. –î–ª—è GPU –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑–º—ñ–Ω–∏—Ç–∏ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é.\n",
        "5. **–î–∞—Ç–∞—Å–µ—Ç–∏**: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –º–µ–Ω—à—ñ –¥–∞—Ç–∞—Å–µ—Ç–∏ –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è.\n",
        "\n",
        "## –î–ª—è –ø–æ–≤–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è:\n",
        "\n",
        "–†–µ–∫–æ–º–µ–Ω–¥—É—î—Ç—å—Å—è –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –ª–æ–∫–∞–ª—å–Ω—É –º–∞—à–∏–Ω—É –∞–±–æ —Å–µ—Ä–≤–µ—Ä –∑:\n",
        "- –ë—ñ–ª—å—à–µ CPU —è–¥–µ—Ä\n",
        "- –ë—ñ–ª—å—à–µ RAM\n",
        "- –°—Ç–∞–±—ñ–ª—å–Ω–∏–º –∂–∏–≤–ª–µ–Ω–Ω—è–º\n",
        "- –ú–æ–∂–ª–∏–≤—ñ—Å—Ç—é –∑–∞–ø—É—Å–∫–∞—Ç–∏ –¥–æ–≤–≥—ñ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "None"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

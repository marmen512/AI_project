"""
–ú–æ–¥—É–ª—å –¥–ª—è –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É —Ä–µ—Å—É—Ä—Å—ñ–≤ –ø—ñ–¥ —á–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è
–í—ñ–¥—Å—Ç–µ–∂—É—î CPU, –ø–∞–º'—è—Ç—å, GPU —Ç–∞ –≤–∏—è–≤–ª—è—î –∞–Ω–æ–º–∞–ª—ñ—ó
"""
import time
import psutil
import torch
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, Optional
import json

# –ù–∞–ª–∞—à—Ç—É–≤–∞—Ç–∏ logger
logger = logging.getLogger(__name__)


class ResourceMonitor:
    """–ú–æ–Ω—ñ—Ç–æ—Ä —Ä–µ—Å—É—Ä—Å—ñ–≤ —Å–∏—Å—Ç–µ–º–∏"""
    
    def __init__(
        self, 
        log_dir: Path = None, 
        log_interval: int = 10,
        cpu_warning_threshold: float = 95.0,
        memory_warning_threshold: float = 90.0,
        gpu_memory_warning_threshold: float = 90.0,
        slow_batch_threshold: float = 300.0
    ):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–Ω—ñ—Ç–æ—Ä–∞
        
        Args:
            log_dir: –ü–∞–ø–∫–∞ –¥–ª—è –ª–æ–≥—ñ–≤ (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º: logs/)
            log_interval: –õ–æ–≥—É–≤–∞—Ç–∏ –∫–æ–∂–Ω—ñ N –±–∞—Ç—á—ñ–≤
            cpu_warning_threshold: –ü–æ—Ä—ñ–≥ –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è –¥–ª—è CPU (%)
            memory_warning_threshold: –ü–æ—Ä—ñ–≥ –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è –¥–ª—è –ø–∞–º'—è—Ç—ñ (%)
            gpu_memory_warning_threshold: –ü–æ—Ä—ñ–≥ –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è –¥–ª—è GPU –ø–∞–º'—è—Ç—ñ (%)
            slow_batch_threshold: –ü–æ—Ä—ñ–≥ –¥–ª—è –≤–∏—è–≤–ª–µ–Ω–Ω—è –ø–æ–≤—ñ–ª—å–Ω–∏—Ö –±–∞—Ç—á—ñ–≤ (—Å–µ–∫—É–Ω–¥–∏)
        """
        if log_dir is None:
            log_dir = Path("logs")
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True, parents=True)
        
        self.log_interval = log_interval
        self.log_file = self.log_dir / f"resource_monitor_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.cpu_samples = []
        self.memory_samples = []
        self.gpu_samples = []
        self.batch_times = []
        
        # –ü–æ—Ä–æ–≥–∏ –¥–ª—è –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω—å (–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –∞–±–æ config)
        self.cpu_warning_threshold = cpu_warning_threshold
        self.memory_warning_threshold = memory_warning_threshold
        self.gpu_memory_warning_threshold = gpu_memory_warning_threshold
        self.slow_batch_threshold = slow_batch_threshold
        
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –ª–æ–≥-—Ñ–∞–π–ª
        self._init_log_file()
    
    def _init_log_file(self):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –ª–æ–≥-—Ñ–∞–π–ª"""
        with open(self.log_file, 'w', encoding='utf-8') as f:
            f.write(f"Resource Monitor Log - Started at {datetime.now().isoformat()}\n")
            f.write("=" * 80 + "\n\n")
    
    def _log(self, message: str):
        """–ó–∞–ø–∏—Å–∞—Ç–∏ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤ –ª–æ–≥"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(f"[{timestamp}] {message}\n")
    
    def get_cpu_usage(self) -> float:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è CPU (%)"""
        return psutil.cpu_percent(interval=0.1)
    
    def get_memory_usage(self) -> Dict[str, float]:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –ø–∞–º'—è—Ç—ñ"""
        mem = psutil.virtual_memory()
        return {
            'percent': mem.percent,
            'used_gb': mem.used / (1024 ** 3),
            'available_gb': mem.available / (1024 ** 3),
            'total_gb': mem.total / (1024 ** 3)
        }
    
    def get_gpu_usage(self) -> Optional[Dict[str, float]]:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è GPU (—è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–æ)"""
        if not torch.cuda.is_available():
            return None
        
        try:
            gpu_memory = torch.cuda.memory_allocated() / (1024 ** 3)  # GB
            gpu_memory_reserved = torch.cuda.memory_reserved() / (1024 ** 3)  # GB
            gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)  # GB
            
            return {
                'memory_allocated_gb': gpu_memory,
                'memory_reserved_gb': gpu_memory_reserved,
                'memory_total_gb': gpu_memory_total,
                'memory_percent': (gpu_memory_reserved / gpu_memory_total) * 100 if gpu_memory_total > 0 else 0
            }
        except Exception as e:
            self._log(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ GPU: {e}")
            return None
    
    def check_resources(self, batch_idx: int, epoch: int, batch_time: Optional[float] = None) -> Dict:
        """
        –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —Ä–µ—Å—É—Ä—Å–∏ —Ç–∞ –∑–∞–ª–æ–≥—É–≤–∞—Ç–∏
        
        Args:
            batch_idx: –Ü–Ω–¥–µ–∫—Å –±–∞—Ç—á–∞
            epoch: –ù–æ–º–µ—Ä –µ–ø–æ—Ö–∏
            batch_time: –ß–∞—Å –æ–±—Ä–æ–±–∫–∏ –±–∞—Ç—á–∞ (—Å–µ–∫—É–Ω–¥–∏)
        
        Returns:
            –°–ª–æ–≤–Ω–∏–∫ –∑ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—î—é –ø—Ä–æ —Ä–µ—Å—É—Ä—Å–∏ —Ç–∞ –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è–º–∏
        """
        cpu_usage = self.get_cpu_usage()
        memory_info = self.get_memory_usage()
        gpu_info = self.get_gpu_usage()
        
        # –ó–±–µ—Ä–µ–≥—Ç–∏ –∑—Ä–∞–∑–∫–∏
        self.cpu_samples.append(cpu_usage)
        self.memory_samples.append(memory_info['percent'])
        if gpu_info:
            self.gpu_samples.append(gpu_info['memory_percent'])
        if batch_time:
            self.batch_times.append(batch_time)
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è
        warnings = []
        
        if cpu_usage > self.cpu_warning_threshold:
            warning_msg = f"–í–∏—Å–æ–∫–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è CPU: {cpu_usage:.1f}% (–ï–ø–æ—Ö–∞: {epoch}, –ë–∞—Ç—á: {batch_idx})"
            warnings.append(f"–í–∏—Å–æ–∫–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è CPU: {cpu_usage:.1f}%")
            logger.warning(warning_msg)
            self._log(f"‚ö†Ô∏è {warning_msg}")
        
        if memory_info['percent'] > self.memory_warning_threshold:
            warning_msg = f"–í–∏—Å–æ–∫–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –ø–∞–º'—è—Ç—ñ: {memory_info['percent']:.1f}% ({memory_info['used_gb']:.2f} GB / {memory_info['total_gb']:.2f} GB) (–ï–ø–æ—Ö–∞: {epoch}, –ë–∞—Ç—á: {batch_idx})"
            warnings.append(f"–í–∏—Å–æ–∫–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –ø–∞–º'—è—Ç—ñ: {memory_info['percent']:.1f}% ({memory_info['used_gb']:.2f} GB / {memory_info['total_gb']:.2f} GB)")
            logger.warning(warning_msg)
            self._log(f"‚ö†Ô∏è {warning_msg}")
        
        if gpu_info and gpu_info['memory_percent'] > self.gpu_memory_warning_threshold:
            warning_msg = f"–í–∏—Å–æ–∫–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è GPU –ø–∞–º'—è—Ç—ñ: {gpu_info['memory_percent']:.1f}% ({gpu_info['memory_reserved_gb']:.2f} GB / {gpu_info['memory_total_gb']:.2f} GB) (–ï–ø–æ—Ö–∞: {epoch}, –ë–∞—Ç—á: {batch_idx})"
            warnings.append(f"–í–∏—Å–æ–∫–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è GPU –ø–∞–º'—è—Ç—ñ: {gpu_info['memory_percent']:.1f}% ({gpu_info['memory_reserved_gb']:.2f} GB / {gpu_info['memory_total_gb']:.2f} GB)")
            logger.warning(warning_msg)
            self._log(f"‚ö†Ô∏è {warning_msg}")
        
        if batch_time and batch_time > self.slow_batch_threshold:
            warning_msg = f"–ü–æ–≤—ñ–ª—å–Ω–∏–π –±–∞—Ç—á: {batch_time:.1f} —Å–µ–∫—É–Ω–¥ (–ï–ø–æ—Ö–∞: {epoch}, –ë–∞—Ç—á: {batch_idx})"
            warnings.append(f"–ü–æ–≤—ñ–ª—å–Ω–∏–π –±–∞—Ç—á: {batch_time:.1f} —Å–µ–∫—É–Ω–¥")
            logger.warning(warning_msg)
            self._log(f"‚ö†Ô∏è {warning_msg}")
        
        # –õ–æ–≥—É–≤–∞—Ç–∏ —Ä–µ—Å—É—Ä—Å–∏ –∫–æ–∂–Ω—ñ N –±–∞—Ç—á—ñ–≤
        if batch_idx % self.log_interval == 0:
            log_msg = f"üìä –†–µ—Å—É—Ä—Å–∏ (–ï–ø–æ—Ö–∞: {epoch}, –ë–∞—Ç—á: {batch_idx}): CPU: {cpu_usage:.1f}%, RAM: {memory_info['percent']:.1f}% ({memory_info['used_gb']:.2f} GB)"
            if gpu_info:
                log_msg += f", GPU: {gpu_info['memory_percent']:.1f}% ({gpu_info['memory_reserved_gb']:.2f} GB)"
            if batch_time:
                log_msg += f", –ß–∞—Å –±–∞—Ç—á–∞: {batch_time:.1f}s"
            self._log(log_msg)
        
        return {
            'cpu_usage': cpu_usage,
            'memory': memory_info,
            'gpu': gpu_info,
            'batch_time': batch_time,
            'warnings': warnings
        }
    
    def should_throttle(self, cpu_usage: Optional[float] = None, memory_info: Optional[Dict] = None) -> bool:
        """
        –ß–∏ –ø–æ—Ç—Ä—ñ–±–Ω–æ throttle (–∑–Ω–∏–∑–∏—Ç–∏ –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è)
        
        Args:
            cpu_usage: –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è CPU (%) (—è–∫—â–æ None, –æ–±—á–∏—Å–ª–∏—Ç—å—Å—è)
            memory_info: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ø–∞–º'—è—Ç—å (—è–∫—â–æ None, –æ–±—á–∏—Å–ª–∏—Ç—å—Å—è)
        
        Returns:
            True —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ throttle
        """
        if cpu_usage is None:
            cpu_usage = self.get_cpu_usage()
        if memory_info is None:
            memory_info = self.get_memory_usage()
        
        # Throttle —è–∫—â–æ CPU –∞–±–æ –ø–∞–º'—è—Ç—å –∑–∞–Ω–∞–¥—Ç–æ –≤–∏—Å–æ–∫—ñ
        if cpu_usage > self.cpu_warning_threshold:
            return True
        if memory_info['percent'] > self.memory_warning_threshold:
            return True
        
        return False
    
    def should_shrink_batch(self, memory_info: Optional[Dict] = None) -> bool:
        """
        –ß–∏ –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑–º–µ–Ω—à–∏—Ç–∏ batch size
        
        Args:
            memory_info: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ø–∞–º'—è—Ç—å (—è–∫—â–æ None, –æ–±—á–∏—Å–ª–∏—Ç—å—Å—è)
        
        Returns:
            True —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ shrink batch
        """
        if memory_info is None:
            memory_info = self.get_memory_usage()
        
        # Shrink batch —è–∫—â–æ –ø–∞–º'—è—Ç—å –¥—É–∂–µ –≤–∏—Å–æ–∫–∞ (> 90%)
        shrink_threshold = 90.0
        if memory_info['percent'] > shrink_threshold:
            return True
        
        return False
    
    def should_pause(self, cpu_usage: Optional[float] = None, memory_info: Optional[Dict] = None) -> bool:
        """
        –ß–∏ –ø–æ—Ç—Ä—ñ–±–Ω–æ –ø—Ä–∏–∑—É–ø–∏–Ω–∏—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è
        
        Args:
            cpu_usage: –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è CPU (%) (—è–∫—â–æ None, –æ–±—á–∏—Å–ª–∏—Ç—å—Å—è)
            memory_info: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ø–∞–º'—è—Ç—å (—è–∫—â–æ None, –æ–±—á–∏—Å–ª–∏—Ç—å—Å—è)
        
        Returns:
            True —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ pause
        """
        if cpu_usage is None:
            cpu_usage = self.get_cpu_usage()
        if memory_info is None:
            memory_info = self.get_memory_usage()
        
        # Pause —è–∫—â–æ –ø–∞–º'—è—Ç—å –∫—Ä–∏—Ç–∏—á–Ω–æ –≤–∏—Å–æ–∫–∞ (> 95%) –∞–±–æ —Å–∏—Å—Ç–µ–º–∞ –ø–µ—Ä–µ–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞
        pause_threshold_memory = 95.0
        if memory_info['percent'] > pause_threshold_memory:
            return True
        
        # Pause —è–∫—â–æ CPU –ø–æ—Å—Ç—ñ–π–Ω–æ > 98%
        if cpu_usage > 98.0:
            return True
        
        return False
    
    def get_throttle_recommendations(self) -> Dict[str, any]:
        """
        –û—Ç—Ä–∏–º–∞—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –ø–æ throttle
        
        Returns:
            Dict –∑ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è–º–∏: throttle, shrink_batch, pause, suggested_batch_size
        """
        cpu_usage = self.get_cpu_usage()
        memory_info = self.get_memory_usage()
        gpu_info = self.get_gpu_usage()
        
        should_throttle = self.should_throttle(cpu_usage, memory_info)
        should_shrink = self.should_shrink_batch(memory_info)
        should_pause = self.should_pause(cpu_usage, memory_info)
        
        return {
            'throttle': should_throttle,
            'shrink_batch': should_shrink,
            'pause': should_pause,
            'cpu_usage': cpu_usage,
            'memory_percent': memory_info['percent'],
            'gpu_memory_percent': gpu_info['memory_percent'] if gpu_info else None
        }
    
    def get_suggested_batch_size(self, current_batch_size: int) -> int:
        """
        –û—Ç—Ä–∏–º–∞—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–∏–π batch size –Ω–∞ –æ—Å–Ω–æ–≤—ñ –ø–æ—Ç–æ—á–Ω–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —Ä–µ—Å—É—Ä—Å—ñ–≤.
        –í–∏–∫–ª–∏–∫–∞—î—Ç—å—Å—è –ø—Ä–∏ OOM –∞–±–æ –≤–∏—Å–æ–∫–æ–º—É –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—ñ –ø–∞–º'—è—Ç—ñ.
        
        Args:
            current_batch_size: –ü–æ—Ç–æ—á–Ω–∏–π batch size
            
        Returns:
            –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–∏–π batch size (–∑–∞–≤–∂–¥–∏ >= 1)
        """
        memory_info = self.get_memory_usage()
        gpu_info = self.get_gpu_usage()
        
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ GPU –ø–∞–º'—è—Ç—å —è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∞, —ñ–Ω–∞–∫—à–µ —Å–∏—Å—Ç–µ–º–Ω—É –ø–∞–º'—è—Ç—å
        memory_percent = gpu_info['memory_percent'] if gpu_info else memory_info['percent']
        
        # –ó–º–µ–Ω—à–∏—Ç–∏ batch size –≤ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –≤—ñ–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –ø–∞–º'—è—Ç—ñ
        if memory_percent > 95.0:
            # –ö—Ä–∏—Ç–∏—á–Ω–æ –≤–∏—Å–æ–∫–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è - –∑–º–µ–Ω—à–∏—Ç–∏ –Ω–∞ 75%
            suggested = max(1, int(current_batch_size * 0.25))
        elif memory_percent > 90.0:
            # –í–∏—Å–æ–∫–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è - –∑–º–µ–Ω—à–∏—Ç–∏ –Ω–∞ 50%
            suggested = max(1, int(current_batch_size * 0.5))
        elif memory_percent > 85.0:
            # –°–µ—Ä–µ–¥–Ω—î-–≤–∏—Å–æ–∫–µ - –∑–º–µ–Ω—à–∏—Ç–∏ –Ω–∞ 25%
            suggested = max(1, int(current_batch_size * 0.75))
        else:
            # –ù–æ—Ä–º–∞–ª—å–Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è - –∑–∞–ª–∏—à–∏—Ç–∏ —è–∫ —î
            suggested = current_batch_size
        
        return suggested
    
    def auto_throttle(self, current_batch_size: int) -> Dict[str, any]:
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π throttle - –ø–æ–≤–µ—Ä—Ç–∞—î —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó —Ç–∞ –Ω–æ–≤–∏–π batch size.
        
        Args:
            current_batch_size: –ü–æ—Ç–æ—á–Ω–∏–π batch size
            
        Returns:
            Dict –∑ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è–º–∏ —Ç–∞ suggested_batch_size
        """
        recommendations = self.get_throttle_recommendations()
        suggested_batch_size = self.get_suggested_batch_size(current_batch_size)
        
        recommendations['suggested_batch_size'] = suggested_batch_size
        recommendations['batch_size_changed'] = suggested_batch_size != current_batch_size
        
        return recommendations
    
    def get_statistics(self) -> Dict:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–µ—Å—É—Ä—Å—ñ–≤"""
        stats = {}
        
        if self.cpu_samples:
            stats['cpu'] = {
                'avg': sum(self.cpu_samples) / len(self.cpu_samples),
                'max': max(self.cpu_samples),
                'min': min(self.cpu_samples)
            }
        
        if self.memory_samples:
            stats['memory'] = {
                'avg_percent': sum(self.memory_samples) / len(self.memory_samples),
                'max_percent': max(self.memory_samples),
                'min_percent': min(self.memory_samples)
            }
        
        if self.gpu_samples:
            stats['gpu'] = {
                'avg_percent': sum(self.gpu_samples) / len(self.gpu_samples),
                'max_percent': max(self.gpu_samples),
                'min_percent': min(self.gpu_samples)
            }
        
        if self.batch_times:
            stats['batch_times'] = {
                'avg': sum(self.batch_times) / len(self.batch_times),
                'max': max(self.batch_times),
                'min': min(self.batch_times)
            }
        
        return stats
    
    def save_statistics(self, filename: str = "resource_statistics.json"):
        """–ó–±–µ—Ä–µ–≥—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ JSON"""
        stats = self.get_statistics()
        stats['log_file'] = str(self.log_file)
        stats['samples_count'] = len(self.cpu_samples)
        
        output_path = self.log_dir / filename
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        return output_path


"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π curriculum tuner
–ê–¥–∞–ø—Ç–∏–≤–Ω–æ –Ω–∞–ª–∞—à—Ç–æ–≤—É—î curriculum –Ω–∞ –æ—Å–Ω–æ–≤—ñ –º–µ—Ç—Ä–∏–∫ –Ω–∞–≤—á–∞–Ω–Ω—è
"""
from typing import Dict, Any, Optional
from dataclasses import dataclass


@dataclass
class CurriculumStage:
    """–ï—Ç–∞–ø curriculum"""
    seq_len: int
    batch_size: int
    learning_rate: float


class AutoCurriculumTuner:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π –Ω–∞–ª–∞—à—Ç—É–≤–∞—á curriculum
    –ê–¥–∞–ø—Ç–∏–≤–Ω–æ –∑–º—ñ–Ω—é—î –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –º–µ—Ç—Ä–∏–∫
    """
    
    def __init__(
        self,
        loss_drop_threshold: float = 0.1,
        min_speed_threshold: float = 1.0,  # tokens/sec
        max_seq_len: int = 512,
        min_batch_size: int = 1,
        seq_len_multiplier: float = 2.0,
        batch_size_step: int = 1
    ):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è tuner'–∞
        
        Args:
            loss_drop_threshold: –ü–æ—Ä—ñ–≥ –∑–Ω–∏–∂–µ–Ω–Ω—è loss –¥–ª—è –∑–±—ñ–ª—å—à–µ–Ω–Ω—è seq_len
            min_speed_threshold: –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å –¥–ª—è –∑–º–µ–Ω—à–µ–Ω–Ω—è batch_size
            max_seq_len: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –¥–æ–≤–∂–∏–Ω–∞ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç—ñ
            min_batch_size: –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–º—ñ—Ä –±–∞—Ç—á—É
            seq_len_multiplier: –ú–Ω–æ–∂–Ω–∏–∫ –¥–ª—è –∑–±—ñ–ª—å—à–µ–Ω–Ω—è seq_len
            batch_size_step: –ö—Ä–æ–∫ –∑–º—ñ–Ω–∏ batch_size
        """
        self.loss_drop_threshold = loss_drop_threshold
        self.min_speed_threshold = min_speed_threshold
        self.max_seq_len = max_seq_len
        self.min_batch_size = min_batch_size
        self.seq_len_multiplier = seq_len_multiplier
        self.batch_size_step = batch_size_step
        
        # –Ü—Å—Ç–æ—Ä—ñ—è –º–µ—Ç—Ä–∏–∫
        self.metrics_history = []
    
    def update(
        self,
        metrics: Dict[str, Any],
        stage: CurriculumStage
    ) -> CurriculumStage:
        """
        –û–Ω–æ–≤–∏—Ç–∏ stage –Ω–∞ –æ—Å–Ω–æ–≤—ñ –º–µ—Ç—Ä–∏–∫
        
        Args:
            metrics: –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞–≤—á–∞–Ω–Ω—è –∑ –∫–ª—é—á–∞–º–∏:
                - loss: –ü–æ—Ç–æ—á–Ω–∏–π loss
                - tokens_per_sec: –®–≤–∏–¥–∫—ñ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó —Ç–æ–∫–µ–Ω—ñ–≤
                - prev_loss: –ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π loss (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
            stage: –ü–æ—Ç–æ—á–Ω–∏–π curriculum stage
        
        Returns:
            –û–Ω–æ–≤–ª–µ–Ω–∏–π stage
        """
        # –ó–±–µ—Ä–µ–≥—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏ –≤ —ñ—Å—Ç–æ—Ä—ñ—é
        self.metrics_history.append(metrics.copy())
        
        # –û–±–º–µ–∂–∏—Ç–∏ —ñ—Å—Ç–æ—Ä—ñ—é
        if len(self.metrics_history) > 100:
            self.metrics_history = self.metrics_history[-100:]
        
        new_stage = CurriculumStage(
            seq_len=stage.seq_len,
            batch_size=stage.batch_size,
            learning_rate=stage.learning_rate
        )
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑–±—ñ–ª—å—à–∏—Ç–∏ seq_len
        current_loss = metrics.get('loss', float('inf'))
        prev_loss = metrics.get('prev_loss')
        
        if prev_loss is not None:
            loss_drop = prev_loss - current_loss
            if loss_drop >= self.loss_drop_threshold:
                # –ó–±—ñ–ª—å—à–∏—Ç–∏ seq_len
                new_seq_len = int(stage.seq_len * self.seq_len_multiplier)
                new_stage.seq_len = min(new_seq_len, self.max_seq_len)
                print(f"üìà –ó–±—ñ–ª—å—à–µ–Ω–æ seq_len: {stage.seq_len} ‚Üí {new_stage.seq_len} (loss drop: {loss_drop:.4f})")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑–º–µ–Ω—à–∏—Ç–∏ batch_size
        tokens_per_sec = metrics.get('tokens_per_sec', float('inf'))
        if tokens_per_sec < self.min_speed_threshold:
            # –ó–º–µ–Ω—à–∏—Ç–∏ batch_size
            new_batch_size = max(stage.batch_size - self.batch_size_step, self.min_batch_size)
            if new_batch_size < stage.batch_size:
                new_stage.batch_size = new_batch_size
                print(f"üìâ –ó–º–µ–Ω—à–µ–Ω–æ batch_size: {stage.batch_size} ‚Üí {new_stage.batch_size} (—à–≤–∏–¥–∫—ñ—Å—Ç—å: {tokens_per_sec:.2f} tokens/sec)")
        
        return new_stage
    
    def get_recommendations(self) -> Dict[str, Any]:
        """
        –û—Ç—Ä–∏–º–∞—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –Ω–∞ –æ—Å–Ω–æ–≤—ñ —ñ—Å—Ç–æ—Ä—ñ—ó –º–µ—Ç—Ä–∏–∫
        
        Returns:
            –°–ª–æ–≤–Ω–∏–∫ –∑ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è–º–∏
        """
        if not self.metrics_history:
            return {}
        
        recent_metrics = self.metrics_history[-10:]  # –û—Å—Ç–∞–Ω–Ω—ñ 10 –∑–∞–ø–∏—Å—ñ–≤
        
        avg_loss = sum(m.get('loss', 0) for m in recent_metrics) / len(recent_metrics)
        avg_speed = sum(m.get('tokens_per_sec', 0) for m in recent_metrics) / len(recent_metrics)
        
        recommendations = {
            'avg_loss': avg_loss,
            'avg_speed': avg_speed,
            'should_increase_seq_len': avg_loss < self.loss_drop_threshold,
            'should_decrease_batch_size': avg_speed < self.min_speed_threshold,
        }
        
        return recommendations


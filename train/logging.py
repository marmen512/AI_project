"""
–†–æ–∑—à–∏—Ä–µ–Ω–∏–π –ª–æ–≥–µ—Ä –¥–ª—è TRM –Ω–∞–≤—á–∞–Ω–Ω—è
–õ–æ–≥—É—î: loss –ø–æ –∫—Ä–æ–∫–∞—Ö, –≥–ª–∏–±–∏–Ω—É —Ä–µ–∫—É—Ä—Å—ñ—ó, entropy, gradient norms
"""
import json
from pathlib import Path
from typing import Dict, List, Optional
import torch
import torch.nn.functional as F


class TRMTrainingLogger:
    """–†–æ–∑—à–∏—Ä–µ–Ω–∏–π –ª–æ–≥–µ—Ä –¥–ª—è TRM –Ω–∞–≤—á–∞–Ω–Ω—è"""
    
    def __init__(self, log_dir: Path = None):
        if log_dir is None:
            log_dir = Path("logs")
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True, parents=True)
        
        self.metrics = {
            'batch_losses': [],
            'step_losses': [],  # Loss –ø–æ recurrent steps
            'recursion_depths': [],  # –ì–ª–∏–±–∏–Ω–∞ —Ä–µ–∫—É—Ä—Å—ñ—ó
            'halt_probs': [],
            'entropies': [],  # Entropy –≤–∏—Ö–æ–¥—É
            'entropy_deltas': [],  # Delta entropy –º—ñ–∂ –∫—Ä–æ–∫–∞–º–∏ recursion
            'depth_vs_entropy': [],  # –ü–∞—Ä–∏ (depth, entropy) –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
            'thinking_costs': [],  # Thinking cost –Ω–∞ sample
            'gradient_norms': []
        }
    
    def log_batch(
        self,
        batch_idx: int,
        epoch: int,
        loss: float,
        step_losses: List[float],  # Loss –Ω–∞ –∫–æ–∂–Ω–æ–º—É recurrent step
        recursion_depths: List[int],
        halt_probs: List[float],
        predictions: torch.Tensor,
        gradients: Optional[torch.Tensor] = None,
        step_entropies: Optional[List[float]] = None,  # Entropy –Ω–∞ –∫–æ–∂–Ω–æ–º—É –∫—Ä–æ—Ü—ñ recursion
        thinking_cost: Optional[float] = None  # Thinking cost –¥–ª—è —Ü—å–æ–≥–æ batch
    ):
        """
        –õ–æ–≥—É–≤–∞—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏ –±–∞—Ç—á–∞
        
        Args:
            step_entropies: –°–ø–∏—Å–æ–∫ entropy –∑–Ω–∞—á–µ–Ω—å –Ω–∞ –∫–æ–∂–Ω–æ–º—É –∫—Ä–æ—Ü—ñ recursion (–¥–ª—è –æ–±—á–∏—Å–ª–µ–Ω–Ω—è delta)
            thinking_cost: Thinking cost –¥–ª—è —Ü—å–æ–≥–æ batch
        """
        # Entropy –≤–∏—Ö–æ–¥—É (–ø–æ—Ç–æ—á–Ω–∞)
        probs = F.softmax(predictions, dim=-1)
        entropy = -(probs * torch.log(probs + 1e-10)).sum(dim=-1).mean().item()
        
        # –û–±—á–∏—Å–ª–∏—Ç–∏ entropy deltas —è–∫—â–æ —î step_entropies
        if step_entropies and len(step_entropies) > 1:
            for i in range(1, len(step_entropies)):
                delta = step_entropies[i] - step_entropies[i-1]
                self.metrics['entropy_deltas'].append(delta)
        
        # Depth vs entropy –ø–∞—Ä–∏ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
        if recursion_depths:
            for depth, ent in zip(recursion_depths, [entropy] * len(recursion_depths)):
                self.metrics['depth_vs_entropy'].append({
                    'depth': depth,
                    'entropy': ent
                })
            # –¢–∞–∫–æ–∂ –¥–æ–¥–∞—Ç–∏ –ø–∞—Ä–∏ –∑ step_entropies —è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω—ñ
            if step_entropies and len(step_entropies) == len(recursion_depths):
                for depth, ent in zip(recursion_depths, step_entropies):
                    self.metrics['depth_vs_entropy'].append({
                        'depth': depth,
                        'entropy': ent
                    })
        
        # Gradient norm
        grad_norm = None
        if gradients is not None:
            grad_norm = gradients.norm().item()
        
        self.metrics['batch_losses'].append({
            'batch': batch_idx,
            'epoch': epoch,
            'loss': loss
        })
        
        self.metrics['step_losses'].extend([
            {'step': i, 'loss': sl} for i, sl in enumerate(step_losses)
        ])
        
        self.metrics['recursion_depths'].extend(recursion_depths)
        self.metrics['halt_probs'].extend(halt_probs)
        self.metrics['entropies'].append(entropy)
        
        if thinking_cost is not None:
            self.metrics['thinking_costs'].append(thinking_cost)
        
        if grad_norm:
            self.metrics['gradient_norms'].append(grad_norm)
    
    def save(self, filename: str = "training_metrics.json"):
        """–ó–±–µ—Ä–µ–≥—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏"""
        output_path = self.log_dir / filename
        with open(output_path, 'w') as f:
            json.dump(self.metrics, f, indent=2)
        return output_path
    
    def get_summary(self) -> Dict:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ –ø—ñ–¥—Å—É–º–æ–∫ –º–µ—Ç—Ä–∏–∫"""
        summary = {}
        
        if self.metrics['batch_losses']:
            summary['avg_loss'] = sum(m['loss'] for m in self.metrics['batch_losses']) / len(self.metrics['batch_losses'])
            summary['min_loss'] = min(m['loss'] for m in self.metrics['batch_losses'])
            summary['max_loss'] = max(m['loss'] for m in self.metrics['batch_losses'])
        
        if self.metrics['recursion_depths']:
            summary['avg_recursion_depth'] = sum(self.metrics['recursion_depths']) / len(self.metrics['recursion_depths'])
            summary['max_recursion_depth'] = max(self.metrics['recursion_depths'])
            summary['min_recursion_depth'] = min(self.metrics['recursion_depths'])
        
        if self.metrics['entropies']:
            summary['avg_entropy'] = sum(self.metrics['entropies']) / len(self.metrics['entropies'])
            summary['min_entropy'] = min(self.metrics['entropies'])
            summary['max_entropy'] = max(self.metrics['entropies'])
        
        # Entropy delta –∞–Ω–∞–ª—ñ–∑
        if self.metrics['entropy_deltas']:
            summary['avg_entropy_delta'] = sum(self.metrics['entropy_deltas']) / len(self.metrics['entropy_deltas'])
            summary['max_entropy_delta'] = max(self.metrics['entropy_deltas'])
            summary['min_entropy_delta'] = min(self.metrics['entropy_deltas'])
        
        # Depth vs entropy –∫–æ—Ä–µ–ª—è—Ü—ñ—è (–ø—Ä–æ—Å—Ç–∏–π –∞–Ω–∞–ª—ñ–∑)
        if self.metrics['depth_vs_entropy']:
            depths = [d['depth'] for d in self.metrics['depth_vs_entropy']]
            entropies = [d['entropy'] for d in self.metrics['depth_vs_entropy']]
            # –ü—Ä–æ—Å—Ç–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—è (–ª–∏—à–µ —è–∫—â–æ –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö)
            if len(depths) > 1:
                import statistics
                try:
                    summary['depth_entropy_correlation'] = {
                        'avg_depth': statistics.mean(depths),
                        'avg_entropy_at_depth': statistics.mean(entropies),
                        'depth_range': (min(depths), max(depths)),
                        'entropy_range': (min(entropies), max(entropies))
                    }
                except:
                    pass
        
        # Thinking cost —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        if self.metrics['thinking_costs']:
            summary['avg_thinking_cost'] = sum(self.metrics['thinking_costs']) / len(self.metrics['thinking_costs'])
            summary['total_thinking_cost'] = sum(self.metrics['thinking_costs'])
        
        if self.metrics['gradient_norms']:
            summary['avg_gradient_norm'] = sum(self.metrics['gradient_norms']) / len(self.metrics['gradient_norms'])
            summary['max_gradient_norm'] = max(self.metrics['gradient_norms'])
        
        if self.metrics['halt_probs']:
            summary['avg_halt_prob'] = sum(self.metrics['halt_probs']) / len(self.metrics['halt_probs'])
        
        return summary
    
    def print_summary(self):
        """–í–∏–≤–µ—Å—Ç–∏ –ø—ñ–¥—Å—É–º–æ–∫ –º–µ—Ç—Ä–∏–∫"""
        summary = self.get_summary()
        print("\n" + "=" * 70)
        print("üìä –ü–Ü–î–°–£–ú–û–ö –ú–ï–¢–†–ò–ö –ù–ê–í–ß–ê–ù–ù–Ø")
        print("=" * 70)
        for key, value in summary.items():
            if isinstance(value, float):
                print(f"   {key}: {value:.4f}")
            else:
                print(f"   {key}: {value}")
        print("=" * 70 + "\n")



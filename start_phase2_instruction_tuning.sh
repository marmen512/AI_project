#!/bin/bash
# –ó–∞–ø—É—Å–∫ –§–ê–ó–ò 2 - Instruction Tuning
# –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ –ø—ñ—Å–ª—è –§–ê–ó–ò 1 –Ω–∞ instruction datasets

set -e  # –ó—É–ø–∏–Ω–∏—Ç–∏ –ø—Ä–∏ –ø–æ–º–∏–ª—Ü—ñ
set -o pipefail

echo "üöÄ –§–ê–ó–ê 2 - Instruction Tuning"
echo "==============================="

# Environment safety defaults
export LC_ALL=${LC_ALL:-C.UTF-8}
export LANG=${LANG:-C.UTF-8}

# Safer CPU threading defaults (can be overridden)
export OMP_NUM_THREADS=${OMP_NUM_THREADS:-6}
export MKL_NUM_THREADS=${MKL_NUM_THREADS:-6}
export OPENBLAS_NUM_THREADS=${OPENBLAS_NUM_THREADS:-6}
export VECLIB_MAXIMUM_THREADS=${VECLIB_MAXIMUM_THREADS:-6}
export NUMEXPR_NUM_THREADS=${NUMEXPR_NUM_THREADS:-6}

# Ensure immediate logs without stdbuf wrapper
export PYTHONUNBUFFERED=1

# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏/–∞–∫—Ç–∏–≤—É–≤–∞—Ç–∏ –≤—ñ—Ä—Ç—É–∞–ª—å–Ω–µ —Å–µ—Ä–µ–¥–æ–≤–∏—â–µ
if [[ "$VIRTUAL_ENV" == "" ]]; then
    if [[ -f "venv-linux/bin/activate" ]]; then
        # shellcheck disable=SC1091
        source venv-linux/bin/activate
    fi
fi

if [[ "$VIRTUAL_ENV" == "" ]]; then
    echo "‚ö†Ô∏è  –ê–∫—Ç–∏–≤—É–π—Ç–µ –≤—ñ—Ä—Ç—É–∞–ª—å–Ω–µ —Å–µ—Ä–µ–¥–æ–≤–∏—â–µ:"
    echo "   source venv-linux/bin/activate"
    exit 1
fi

# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ –∑ –§–ê–ó–ò 1
PHASE1_MODEL="checkpoints/phase1/best_model.pt"
if [[ ! -f "$PHASE1_MODEL" ]]; then
    echo "‚ùå –ú–æ–¥–µ–ª—å –∑ –§–ê–ó–ò 1 –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞!"
    echo "   –û—á—ñ–∫—É—î—Ç—å—Å—è: $PHASE1_MODEL"
    echo "   –°–ø–æ—á–∞—Ç–∫—É –∑–∞–≤–µ—Ä—à—ñ—Ç—å –§–ê–ó–£ 1: ./start_phase1_pretraining.sh"
    exit 1
fi

# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ instruction datasets
echo "üìö –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ instruction datasets:"
DATASETS_FOUND=0

for dataset in "datasets/alpaca.json" "datasets/squad.json" "datasets/squad_v2.json" "datasets/dailydialog_minimal.json"; do
    if [[ -f "$dataset" ]]; then
        echo "   ‚úÖ $dataset"
        DATASETS_FOUND=$((DATASETS_FOUND + 1))
    else
        echo "   ‚ùå $dataset (–Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ)"
    fi
done

if [[ $DATASETS_FOUND -eq 0 ]]; then
    echo "‚ùå –ñ–æ–¥–µ–Ω instruction dataset –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ!"
    echo "   –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –ø–∞–ø–∫—É datasets/"
    exit 1
fi

echo "   üìä –ó–Ω–∞–π–¥–µ–Ω–æ $DATASETS_FOUND instruction datasets"

# –ü–æ–∫–∞–∑–∞—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –º–æ–¥–µ–ª—å –∑ –§–ê–ó–ò 1
echo ""
echo "üîó –ú–æ–¥–µ–ª—å –∑ –§–ê–ó–ò 1:"
echo "   –§–∞–π–ª: $PHASE1_MODEL"

# –ù–∞–¥—ñ–π–Ω–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ä–æ–∑–º—ñ—Ä—É —Ñ–∞–π–ª—É
if [ -f "$PHASE1_MODEL" ]; then
    MODEL_SIZE=$(stat -c%s "$PHASE1_MODEL")
    echo "   –†–æ–∑–º—ñ—Ä: $((MODEL_SIZE / 1024 / 1024))MB ($MODEL_SIZE –±–∞–π—Ç)"
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —â–æ —Ü–µ –¥—ñ–π—Å–Ω–æ checkpoint —Ñ–∞–π–ª
    if [ "$MODEL_SIZE" -lt 1000000 ]; then
        echo "‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –∑–∞–Ω–∞–¥—Ç–æ –º–∞–ª–∞ (< 1MB), –º–æ–∂–ª–∏–≤–æ –ø–æ—à–∫–æ–¥–∂–µ–Ω–∞"
    fi
else
    echo "   ‚ùå –ü–û–ú–ò–õ–ö–ê: –§–∞–π–ª –Ω–µ —ñ—Å–Ω—É—î!"
    exit 1
fi

# –ü–æ–∫–∞–∑–∞—Ç–∏ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é
echo ""
echo "üìã –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –§–ê–ó–ò 2:"
echo "   Config: config/phase2_instruction_tuning.yaml"
echo "   Base model: –ó –§–ê–ó–ò 1 (pretrained –Ω–∞ Simple Wikipedia)"
echo "   Objective: Instruction Following"
echo "   Max epochs: 1-2 (–∑ early stopping)"
echo "   Datasets: Alpaca, SQuAD, DailyDialog"

# –°—Ç–≤–æ—Ä–∏—Ç–∏ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ –ø–∞–ø–∫–∏
mkdir -p checkpoints/phase2
mkdir -p logs/phase2

echo ""
echo "üéØ –ó–∞–ø—É—Å–∫ instruction tuning –§–ê–ó–ò 2..."
echo "   –¶–µ –∑–∞–π–º–µ –º–µ–Ω—à–µ —á–∞—Å—É –Ω—ñ–∂ –§–ê–ó–ê 1"
echo "   –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥: tail -f logs/phase2/phase2_instruction_tuning.log"
echo "   Live stdout: tail -f logs/phase2/live_stdout.log"

# –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è
set +e
python -u scripts/train_phase2_instruction_tuning.py \
    --config config/phase2_instruction_tuning.yaml \
    --phase1-model "$PHASE1_MODEL" \
    2>&1 | tee -a logs/phase2/live_stdout.log
PY_STATUS=${PIPESTATUS[0]}
set -e

echo ""
if [[ $PY_STATUS -eq 0 ]]; then
    echo "‚úÖ –§–ê–ó–ê 2 –∑–∞–≤–µ—Ä—à–µ–Ω–∞!"
    echo "   –§—ñ–Ω–∞–ª—å–Ω–∞ –º–æ–¥–µ–ª—å: checkpoints/phase2/best_instruction_model.pt"
    echo ""
    echo "üéâ –î–≤–æ—Ñ–∞–∑–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ!"
    echo "   üìö –§–ê–ó–ê 1: Language pretraining ‚úÖ"
    echo "   üéØ –§–ê–ó–ê 2: Instruction tuning ‚úÖ"
    echo ""
    echo "ü§ñ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è!"
    echo "   –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è: python scripts/test_model.py --model checkpoints/phase2/best_instruction_model.pt"
elif [[ $PY_STATUS -eq 130 ]]; then
    echo "‚ö†Ô∏è  –§–ê–ó–ê 2 –∑—É–ø–∏–Ω–µ–Ω–∞ (Ctrl+C). –ü—Ä–æ–≥—Ä–µ—Å –∑–±–µ—Ä–µ–∂–µ–Ω–æ."
    echo "   Resume: checkpoints/phase2/last_checkpoint.pt"
    exit 130
else
    echo "‚ùå –§–ê–ó–ê 2 –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å –∑ –ø–æ–º–∏–ª–∫–æ—é (exit code: $PY_STATUS)"
    echo "   –ü–µ—Ä–µ–≤—ñ—Ä –ª–æ–≥–∏: logs/phase2/phase2_instruction_tuning.log"
    echo "   Live stdout: logs/phase2/live_stdout.log"
fi

exit $PY_STATUS

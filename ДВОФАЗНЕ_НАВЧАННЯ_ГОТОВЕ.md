# ‚úÖ –î–≤–æ—Ñ–∞–∑–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è –∫–∞—Å—Ç–æ–º–Ω–æ—ó TRM –º–æ–¥–µ–ª—ñ - –ì–û–¢–û–í–ï!

## üéØ –©–æ –±—É–ª–æ –∑—Ä–æ–±–ª–µ–Ω–æ

–í–∞—à –ø—Ä–æ–µ–∫—Ç —É—Å–ø—ñ—à–Ω–æ –∞–¥–∞–ø—Ç–æ–≤–∞–Ω–æ –¥–ª—è **–¥–≤–æ—Ñ–∞–∑–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è** –∫–∞—Å—Ç–æ–º–Ω–æ—ó Transformer –º–æ–¥–µ–ª—ñ –∑ –Ω—É–ª—è –∑–≥—ñ–¥–Ω–æ –∑ —É—Å—ñ–º–∞ –≤–∏–º–æ–≥–∞–º–∏.

### ‚úÖ –§–ê–ó–ê 1 - Language Pretraining (–ì–û–¢–û–í–ê)

**–î–∞—Ç–∞—Å–µ—Ç:**
- ‚úÖ `datasets/pretrain_text.txt` - 85.4 MB plain text
- ‚úÖ 314,218 —Å—Ç–∞—Ç–µ–π Simple Wikipedia
- ‚úÖ 19,999,911 —Ç–æ–∫–µ–Ω—ñ–≤ (–≤ –º–µ–∂–∞—Ö 15-20M –ª—ñ–º—ñ—Ç—É)
- ‚úÖ Newlines –∑–∞–º—ñ–Ω–µ–Ω—ñ –Ω–∞ spaces
- ‚úÖ –ë–ï–ó instruction format

**–ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è:**
- ‚úÖ `config/phase1_pretraining.yaml`
- ‚úÖ Small Transformer (~15M –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤)
- ‚úÖ Random initialization (transformer_pretrained: false)
- ‚úÖ GPT-2 tokenizer (–ù–ï –ø–µ—Ä–µ–Ω–∞–≤—á—É—î—Ç—å—Å—è)
- ‚úÖ Causal language modeling objective
- ‚úÖ CPU-only –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
- ‚úÖ –ú–∞–∫—Å–∏–º—É–º 3 epochs

**–°–∫—Ä–∏–ø—Ç–∏:**
- ‚úÖ `scripts/prepare_phase1_dataset.py` - –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ plain text
- ‚úÖ `scripts/train_phase1_pretraining.py` - –Ω–∞–≤—á–∞–Ω–Ω—è –§–ê–ó–ò 1
- ‚úÖ `start_phase1_pretraining.sh` - –∑—Ä—É—á–Ω–∏–π –∑–∞–ø—É—Å–∫

### ‚úÖ –§–ê–ó–ê 2 - Instruction Tuning (–ì–û–¢–û–í–ê)

**–î–∞—Ç–∞—Å–µ—Ç–∏:**
- ‚úÖ `datasets/alpaca.json` - 22.4 MB (Alpaca instructions)
- ‚úÖ `datasets/squad.json` - 79.9 MB (SQuAD 1.1 Q&A)
- ‚úÖ `datasets/squad_v2.json` - 79.3 MB (SQuAD v2 Q&A)
- ‚úÖ `datasets/dailydialog_minimal.json` - 670 B (DailyDialog)

**–ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è:**
- ‚úÖ `config/phase2_instruction_tuning.yaml`
- ‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è weights –∑ –§–ê–ó–ò 1
- ‚úÖ Instruction following objective
- ‚úÖ –ú–∞–∫—Å–∏–º—É–º 2 epochs –∑ early stopping
- ‚úÖ –ë–∞–ª–∞–Ω—Å—É–≤–∞–Ω–Ω—è datasets

**–°–∫—Ä–∏–ø—Ç–∏:**
- ‚úÖ `scripts/train_phase2_instruction_tuning.py` - –Ω–∞–≤—á–∞–Ω–Ω—è –§–ê–ó–ò 2
- ‚úÖ `start_phase2_instruction_tuning.sh` - –∑—Ä—É—á–Ω–∏–π –∑–∞–ø—É—Å–∫

### ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è

- ‚úÖ `TWO_PHASE_TRAINING_README.md` - –ø–æ–≤–Ω–∏–π –≥—ñ–¥ –ø–æ –¥–≤–æ—Ñ–∞–∑–Ω–æ–º—É –Ω–∞–≤—á–∞–Ω–Ω—é
- ‚úÖ `–î–í–û–§–ê–ó–ù–ï_–ù–ê–í–ß–ê–ù–ù–Ø_–ì–û–¢–û–í–ï.md` - —Ü–µ–π –∑–≤—ñ—Ç

## üöÄ –Ø–∫ –∑–∞–ø—É—Å—Ç–∏—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è

### 1. –§–ê–ó–ê 1 - Language Pretraining

```bash
# –ê–∫—Ç–∏–≤—É–≤–∞—Ç–∏ –≤—ñ—Ä—Ç—É–∞–ª—å–Ω–µ —Å–µ—Ä–µ–¥–æ–≤–∏—â–µ
source venv/bin/activate

# –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –§–ê–ó–£ 1 (4-8 –≥–æ–¥–∏–Ω –Ω–∞ CPU)
./start_phase1_pretraining.sh
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** `checkpoints/phase1/best_model.pt`

### 2. –§–ê–ó–ê 2 - Instruction Tuning

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –§–ê–ó–£ 2 –ø—ñ—Å–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –§–ê–ó–ò 1 (1-3 –≥–æ–¥–∏–Ω–∏ –Ω–∞ CPU)
./start_phase2_instruction_tuning.sh
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** `checkpoints/phase2/best_instruction_model.pt`

## üìä –¢–µ—Ö–Ω—ñ—á–Ω—ñ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏

### –ú–æ–¥–µ–ª—å
- **–ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞**: Small Transformer (GPT-2 based)
- **–ü–∞—Ä–∞–º–µ—Ç—Ä–∏**: ~15M (dim=512, depth=8)
- **Sequence Length**: 256 —Ç–æ–∫–µ–Ω—ñ–≤
- **Vocab Size**: 50,257 (GPT-2)
- **–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è**: Random weights –≤ –§–ê–ó–Ü 1

### –û–±–ª–∞–¥–Ω–∞–Ω–Ω—è (CPU-only)
- **CPU**: Ryzen 5 3600 (6c/12t) ‚úÖ
- **RAM**: 20 GB DDR4 ‚úÖ
- **Swap**: 120 GB ‚úÖ
- **GPU**: RX560 (–ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è) ‚úÖ

### –î–∞—Ç–∞—Å–µ—Ç–∏
- **–§–ê–ó–ê 1**: Simple Wikipedia plain text (~20M —Ç–æ–∫–µ–Ω—ñ–≤)
- **–§–ê–ó–ê 2**: Alpaca + SQuAD 1.1 + SQuAD v2 + DailyDialog

## ‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–Ω—ñ –≤–∏–º–æ–≥–∏ (–î–û–¢–†–ò–ú–ê–ù–û)

### ‚úÖ –î–æ—Ç—Ä–∏–º–∞–Ω–æ –≤—Å—ñ –≤–∏–º–æ–≥–∏:

1. ‚úÖ **–ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è instruction datasets –≤ –§–ê–ó–Ü 1**
2. ‚úÖ **–ù–ï –∑–º—ñ—à—É—é—Ç—å—Å—è RAG –¥–∞–Ω—ñ –ø—ñ–¥ —á–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è**
3. ‚úÖ **–ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è pretrained weights –≤ –§–ê–ó–Ü 1**
4. ‚úÖ **–ù–ï –ø–µ—Ä–µ–Ω–∞–≤—á—É—î—Ç—å—Å—è tokenizer**
5. ‚úÖ **–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è —Ç—ñ–ª—å–∫–∏ CPU**
6. ‚úÖ **–ú–∞–∫—Å–∏–º—É–º 3 epochs –¥–ª—è –§–ê–ó–ò 1**
7. ‚úÖ **–ú–∞–∫—Å–∏–º—É–º 2 epochs –¥–ª—è –§–ê–ó–ò 2**
8. ‚úÖ **GPT-2 tokenizer —è–∫ –≤–∏–º–∞–≥–∞—î—Ç—å—Å—è**
9. ‚úÖ **Simple Wikipedia —è–∫ plain text**
10. ‚úÖ **–î–æ–∑–≤–æ–ª–µ–Ω—ñ instruction datasets –¥–ª—è –§–ê–ó–ò 2**

## üéâ –û—á—ñ–∫—É–≤–∞–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏

### –ü—ñ—Å–ª—è –§–ê–ó–ò 1:
- –ú–æ–¥–µ–ª—å —Ä–æ–∑—É–º—ñ—î —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∞–Ω–≥–ª—ñ–π—Å—å–∫–æ—ó –º–æ–≤–∏
- –ú–æ–∂–µ –≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –∑–≤'—è–∑–Ω–∏–π —Ç–µ–∫—Å—Ç
- Loss –∑–Ω–∏–∂—É—î—Ç—å—Å—è –∑ ~8-10 –¥–æ ~3-4

### –ü—ñ—Å–ª—è –§–ê–ó–ò 2:
- –ú–æ–¥–µ–ª—å –ø–æ–≤–æ–¥–∏—Ç—å—Å—è —è–∫ AI-–∞—Å–∏—Å—Ç–µ–Ω—Ç
- –í—ñ–¥–ø–æ–≤—ñ–¥–∞—î –Ω–∞ –ø–∏—Ç–∞–Ω–Ω—è —Ç–∞ –≤–∏–∫–æ–Ω—É—î —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó
- Loss –∑–Ω–∏–∂—É—î—Ç—å—Å—è –∑ ~3-4 –¥–æ ~2-3
- –ì–æ—Ç–æ–≤–∞ –¥–ª—è —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è RAG —Å–∏—Å—Ç–µ–º–æ—é

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç—É

```
‚îú‚îÄ‚îÄ üöÄ –ó–∞–ø—É—Å–∫ –Ω–∞–≤—á–∞–Ω–Ω—è
‚îÇ   ‚îú‚îÄ‚îÄ start_phase1_pretraining.sh      ‚úÖ –ì–æ—Ç–æ–≤–∏–π
‚îÇ   ‚îî‚îÄ‚îÄ start_phase2_instruction_tuning.sh ‚úÖ –ì–æ—Ç–æ–≤–∏–π
‚îÇ
‚îú‚îÄ‚îÄ üìã –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
‚îÇ   ‚îú‚îÄ‚îÄ config/phase1_pretraining.yaml   ‚úÖ –ì–æ—Ç–æ–≤–∏–π
‚îÇ   ‚îî‚îÄ‚îÄ config/phase2_instruction_tuning.yaml ‚úÖ –ì–æ—Ç–æ–≤–∏–π
‚îÇ
‚îú‚îÄ‚îÄ üîß –°–∫—Ä–∏–ø—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è
‚îÇ   ‚îú‚îÄ‚îÄ scripts/prepare_phase1_dataset.py ‚úÖ –ì–æ—Ç–æ–≤–∏–π
‚îÇ   ‚îú‚îÄ‚îÄ scripts/train_phase1_pretraining.py ‚úÖ –ì–æ—Ç–æ–≤–∏–π
‚îÇ   ‚îî‚îÄ‚îÄ scripts/train_phase2_instruction_tuning.py ‚úÖ –ì–æ—Ç–æ–≤–∏–π
‚îÇ
‚îú‚îÄ‚îÄ üìö –î–∞—Ç–∞—Å–µ—Ç–∏
‚îÇ   ‚îú‚îÄ‚îÄ datasets/pretrain_text.txt       ‚úÖ 85.4 MB –≥–æ—Ç–æ–≤–∏–π
‚îÇ   ‚îú‚îÄ‚îÄ datasets/alpaca.json            ‚úÖ 22.4 MB –≥–æ—Ç–æ–≤–∏–π
‚îÇ   ‚îú‚îÄ‚îÄ datasets/squad.json             ‚úÖ 79.9 MB –≥–æ—Ç–æ–≤–∏–π
‚îÇ   ‚îú‚îÄ‚îÄ datasets/squad_v2.json          ‚úÖ 79.3 MB –≥–æ—Ç–æ–≤–∏–π
‚îÇ   ‚îî‚îÄ‚îÄ datasets/dailydialog_minimal.json ‚úÖ 670 B –≥–æ—Ç–æ–≤–∏–π
‚îÇ
‚îî‚îÄ‚îÄ üìñ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è
    ‚îú‚îÄ‚îÄ TWO_PHASE_TRAINING_README.md     ‚úÖ –ì–æ—Ç–æ–≤–∏–π
    ‚îî‚îÄ‚îÄ –î–í–û–§–ê–ó–ù–ï_–ù–ê–í–ß–ê–ù–ù–Ø_–ì–û–¢–û–í–ï.md      ‚úÖ –¶–µ–π —Ñ–∞–π–ª
```

## üî• –ì–æ—Ç–æ–≤–Ω—ñ—Å—Ç—å –¥–æ –∑–∞–ø—É—Å–∫—É: 100%

**–í—Å–µ –≥–æ—Ç–æ–≤–æ –¥–ª—è –ø–æ—á–∞—Ç–∫—É –¥–≤–æ—Ñ–∞–∑–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è!**

–ü—Ä–æ—Å—Ç–æ –∑–∞–ø—É—Å—Ç—ñ—Ç—å:
```bash
source venv/bin/activate
./start_phase1_pretraining.sh
```

–ü—ñ—Å–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –§–ê–ó–ò 1:
```bash
./start_phase2_instruction_tuning.sh
```

**–£—Å–ø—ñ—à–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è! üöÄ**



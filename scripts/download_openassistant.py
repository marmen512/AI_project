"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó OpenAssistant –¥–∞—Ç–∞—Å–µ—Ç—É
"""
import json
import sys
from pathlib import Path

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from datasets import load_dataset
except ImportError:
    print("‚ùå –ü–æ—Ç—Ä—ñ–±–Ω–æ –≤—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ datasets: pip install datasets")
    sys.exit(1)


def convert_to_format(dataset, max_examples=None, split_name="train"):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç—É–≤–∞—Ç–∏ OpenAssistant –¥–∞—Ç–∞—Å–µ—Ç —É —Ñ–æ—Ä–º–∞—Ç –ø—Ä–æ–µ–∫—Ç—É
    
    Args:
        dataset: Hugging Face dataset
        max_examples: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ (None = –≤—Å—ñ)
        split_name: –ù–∞–∑–≤–∞ split'—É –¥–ª—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
    
    Returns:
        –°–ø–∏—Å–æ–∫ –∫–æ–Ω–≤–µ—Ä—Ç–æ–≤–∞–Ω–∏—Ö –ø—Ä–∏–∫–ª–∞–¥—ñ–≤
    """
    data = []
    count = 0
    
    print(f"üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è {split_name} –¥–∞—Ç–∞—Å–µ—Ç—É...")
    
    for item in dataset:
        # OpenAssistant –º–∞—î —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∑ message_id, parent_id, text, role
        text = item.get('text', '')
        role = item.get('role', 'assistant')
        
        # –§—ñ–ª—å—Ç—Ä –∑–∞ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–æ—é –¥–æ–≤–∂–∏–Ω–æ—é
        if len(text) > 50:
            # –°—Ç–≤–æ—Ä–∏—Ç–∏ context/query/completion —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            if len(text) > 200:
                # –†–æ–∑–¥—ñ–ª–∏—Ç–∏ –¥–æ–≤–≥–∏–π —Ç–µ–∫—Å—Ç –Ω–∞ context —Ç–∞ completion
                mid = len(text) // 2
                data.append({
                    'context': text[:mid],
                    'query': f'Continue this {role} message',
                    'completion': text[mid:]
                })
            else:
                # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç—ñ–≤ - —Å—Ç–≤–æ—Ä–∏—Ç–∏ –ø–∞—Ä—É –∑ query
                data.append({
                    'context': '',
                    'query': f'Generate a {role} response',
                    'completion': text
                })
            
            count += 1
            if max_examples and count >= max_examples:
                break
        
        # –ü—Ä–æ–≥—Ä–µ—Å –∫–æ–∂–Ω—ñ 100 –ø—Ä–∏–∫–ª–∞–¥—ñ–≤
        if count % 100 == 0 and count > 0:
            print(f"   ‚úÖ –û–±—Ä–æ–±–ª–µ–Ω–æ {count} –ø—Ä–∏–∫–ª–∞–¥—ñ–≤...")
    
    return data


def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    print("=" * 80)
    print("üì• –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –¢–ê –ö–û–ù–í–ï–†–¢–ê–¶–Ü–Ø OPENASSISTANT –î–ê–¢–ê–°–ï–¢–£")
    print("=" * 80)
    
    # –°—Ç–≤–æ—Ä–∏—Ç–∏ –ø–∞–ø–∫–∏ —è–∫—â–æ –Ω–µ —ñ—Å–Ω—É—é—Ç—å
    train_dir = project_root / "datasets" / "train"
    eval_dir = project_root / "datasets" / "eval"
    raw_dir = project_root / "datasets" / "raw"
    
    train_dir.mkdir(parents=True, exist_ok=True)
    eval_dir.mkdir(parents=True, exist_ok=True)
    raw_dir.mkdir(parents=True, exist_ok=True)
    
    print("\nüìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫:")
    print(f"   Training: {train_dir}")
    print(f"   Eval: {eval_dir}")
    print(f"   Raw: {raw_dir}")
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç–∏
    print("\nüì• –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ Hugging Face...")
    try:
        train_dataset = load_dataset(
            "OpenAssistant/oasst_top1_2023-08-25", 
            split="train"
        )
        eval_dataset = load_dataset(
            "OpenAssistant/oasst_top1_2023-08-25", 
            split="test"  # –í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ: –¥–∞—Ç–∞—Å–µ—Ç –º–∞—î split "test" –∑–∞–º—ñ—Å—Ç—å "eval"
        )
        
        print(f"‚úÖ Training: {len(train_dataset)} –ø—Ä–∏–∫–ª–∞–¥—ñ–≤")
        print(f"‚úÖ Eval: {len(eval_dataset)} –ø—Ä–∏–∫–ª–∞–¥—ñ–≤")
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {e}")
        return
    
    # –ö–æ–Ω–≤–µ—Ä—Ç—É–≤–∞—Ç–∏ training –¥–∞—Ç–∞—Å–µ—Ç
    print("\n" + "=" * 80)
    print("üîÑ –ö–û–ù–í–ï–†–¢–ê–¶–Ü–Ø TRAINING –î–ê–¢–ê–°–ï–¢–£")
    print("=" * 80)
    
    train_data = convert_to_format(train_dataset, max_examples=2000, split_name="train")
    
    # –ó–±–µ—Ä–µ–≥—Ç–∏ training –¥–∞—Ç–∞—Å–µ—Ç
    train_output = train_dir / "openassistant_train.json"
    with open(train_output, 'w', encoding='utf-8') as f:
        json.dump({
            'metadata': {
                'source': 'OpenAssistant/oasst_top1_2023-08-25',
                'split': 'train',
                'num_examples': len(train_data),
                'original_size': len(train_dataset)
            },
            'data': train_data
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\n‚úÖ Training –¥–∞—Ç–∞—Å–µ—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ:")
    print(f"   üìÅ {train_output}")
    print(f"   üìä {len(train_data)} –ø—Ä–∏–∫–ª–∞–¥—ñ–≤")
    
    # –ö–æ–Ω–≤–µ—Ä—Ç—É–≤–∞—Ç–∏ eval –¥–∞—Ç–∞—Å–µ—Ç
    print("\n" + "=" * 80)
    print("üîÑ –ö–û–ù–í–ï–†–¢–ê–¶–Ü–Ø EVAL –î–ê–¢–ê–°–ï–¢–£")
    print("=" * 80)
    
    eval_data = convert_to_format(eval_dataset, max_examples=500, split_name="eval")
    
    # –ó–±–µ—Ä–µ–≥—Ç–∏ eval –¥–∞—Ç–∞—Å–µ—Ç
    eval_output = eval_dir / "openassistant_eval.json"
    with open(eval_output, 'w', encoding='utf-8') as f:
        json.dump({
            'metadata': {
                'source': 'OpenAssistant/oasst_top1_2023-08-25',
                'split': 'eval',
                'num_examples': len(eval_data),
                'original_size': len(eval_dataset)
            },
            'data': eval_data
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\n‚úÖ Eval –¥–∞—Ç–∞—Å–µ—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ:")
    print(f"   üìÅ {eval_output}")
    print(f"   üìä {len(eval_data)} –ø—Ä–∏–∫–ª–∞–¥—ñ–≤")
    
    # –ü—ñ–¥—Å—É–º–æ–∫
    print("\n" + "=" * 80)
    print("‚úÖ –ó–ê–í–ï–†–®–ï–ù–û!")
    print("=" * 80)
    print(f"\nüìä –ü—ñ–¥—Å—É–º–æ–∫:")
    print(f"   Training: {len(train_data)} –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ ‚Üí {train_output}")
    print(f"   Eval: {len(eval_data)} –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ ‚Üí {eval_output}")
    print(f"\nüöÄ –¢–µ–ø–µ—Ä –º–æ–∂–Ω–∞ –Ω–∞–≤—á–∞—Ç–∏ –º–æ–¥–µ–ª—å:")
    print(f"   python scripts/train_model.py --dataset datasets/train/openassistant_train.json")
    print(f"\nüß™ –ê–±–æ —Ç–µ—Å—Ç—É–≤–∞—Ç–∏:")
    print(f"   python scripts/test_model.py --dataset datasets/eval/openassistant_eval.json")


if __name__ == "__main__":
    main()


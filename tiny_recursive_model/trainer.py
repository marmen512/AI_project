from __future__ import annotations

import torch
import torch.nn.functional as F
import time
import os
import sys
from datetime import timedelta
from pathlib import Path
from torch.nn import Module
from torch.optim import AdamW, Optimizer
from torch.optim.lr_scheduler import LambdaLR
from torch.utils.data import Dataset, DataLoader

from einops import pack, unpack

from accelerate import Accelerator

# ema - apparently greatly helped with results

from ema_pytorch import EMA

from tiny_recursive_model.trm import TinyRecursiveModel
from core.types import TrainState
from runtime.checkpointing import CheckpointManager
from core.constants import CHECKPOINT_BEST_LOSS, CHECKPOINT_BEST_EVAL, CHECKPOINT_BEST_ENTROPY
from train.callbacks.base import CallbackList
from train.callbacks.curriculum import CurriculumCallback
from train.callbacks.checkpoint import CheckpointCallback
from train.callbacks.logging import LoggingCallback
from train.callbacks.early_stopping import EarlyStoppingCallback

from adam_atan2_pytorch import MuonAdamAtan2

from x_transformers import Encoder, Decoder

try:
    from tqdm import tqdm
    HAS_TQDM = True
except ImportError:
    HAS_TQDM = False

# helpers

def exists(v):
    return v is not None

def range_from_one(n):
    return range(1, n + 1)

def is_empty(t):
    return t.numel() == 0

# trainer

class Trainer(Module):
    def __init__(
        self,
        model: TinyRecursiveModel | Module,
        dataset: Dataset,
        optim_klass = AdamW,
        optim: Optimizer | None = None,
        learning_rate = 1e-4,
        muon_learning_rate = 1e-3,
        weight_decay = 1.,
        batch_size = 16,
        epochs = 2,
        halt_prob_thres = 0.5,
        max_recurrent_steps = 12,
        thinking_cost_weight: float = 0.01,  # –í–∞–≥–∞ thinking cost –≤ loss
        warmup_steps = 2000,
        ema_decay_rate = 0.999,
        switch_ema_every = 10000,           # switch ema https://arxiv.org/abs/2402.09240
        accelerate_kwargs: dict = dict(),
        cpu = False,
        checkpoint_dir: str | None = None,
        checkpoint_interval: int = 100,  # –ó–±–µ—Ä—ñ–≥–∞—Ç–∏ checkpoint –∫–æ–∂–Ω—ñ N –±–∞—Ç—á—ñ–≤
        log_file: str | Path | None = None,  # –§–∞–π–ª –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥—É–≤–∞–Ω–Ω—è
        resource_monitor = None,  # ResourceMonitor –¥–ª—è –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É —Ä–µ—Å—É—Ä—Å—ñ–≤
        training_logger = None,  # TRMTrainingLogger –¥–ª—è –ª–æ–≥—É–≤–∞–Ω–Ω—è –º–µ—Ç—Ä–∏–∫
        curriculum_scheduler = None,  # CurriculumScheduler –¥–ª—è –∫–µ—Ä—É–≤–∞–Ω–Ω—è –µ—Ç–∞–ø–∞–º–∏ –Ω–∞–≤—á–∞–Ω–Ω—è
        callbacks: list = None  # –°–ø–∏—Å–æ–∫ callbacks (–¥–ª—è callback-based –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏)
    ):
        super().__init__()

        self.accelerator  = Accelerator(**accelerate_kwargs, cpu = cpu)

        self.batch_size = batch_size
        self.epochs = epochs
        
        # –õ–æ–≥—É–≤–∞–Ω–Ω—è –≤ —Ñ–∞–π–ª
        self.log_file = None
        if log_file is not None:
            self.log_file = Path(log_file)
            self.log_file.parent.mkdir(exist_ok=True, parents=True)
            # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –ª–æ–≥-—Ñ–∞–π–ª
            with open(self.log_file, 'w', encoding='utf-8') as f:
                f.write(f"Training Log - Started at {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("=" * 80 + "\n\n")
        
        # –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å—ñ–≤ —Ç–∞ –ª–æ–≥—É–≤–∞–Ω–Ω—è
        self.resource_monitor = resource_monitor
        self.training_logger = training_logger
        self.curriculum_scheduler = curriculum_scheduler
        
        # Callback-based –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞
        self.callbacks = CallbackList(callbacks or [])
        
        # –î–æ–¥–∞—Ç–∏ callbacks —è–∫—â–æ –≤–æ–Ω–∏ –ø–µ—Ä–µ–¥–∞–Ω—ñ —á–µ—Ä–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
        if curriculum_scheduler is not None:
            self.callbacks.add(CurriculumCallback(curriculum_scheduler))
        if training_logger is not None:
            self.callbacks.add(LoggingCallback(training_logger))
        if checkpoint_dir is not None:
            # CheckpointCallback –±—É–¥–µ —Å—Ç–≤–æ—Ä–µ–Ω–æ –ø—ñ–∑–Ω—ñ—à–µ –ø—ñ—Å–ª—è —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó checkpoint_manager
            pass

        # data

        self.dataset = dataset
        self.dataloader = dataloader = DataLoader(self.dataset, batch_size = self.batch_size, shuffle = True)

        # optim

        if not exists(optim):

            if isinstance(model.network, (Encoder, Decoder)):
                optim = MuonAdamAtan2(
                    model.network.muon_parameters(),
                    model.parameters(),
                    lr = learning_rate / (batch_size * max_recurrent_steps),
                    muon_lr = muon_learning_rate / (batch_size * max_recurrent_steps),
                    weight_decay = weight_decay
                )
            else:
                optim = optim_klass(
                    model.parameters(),
                    lr = learning_rate / (batch_size * max_recurrent_steps),
                    weight_decay = weight_decay
                )

        self.optim = optim

        # scheduler

        self.scheduler = LambdaLR(self.optim, lambda step: min((step + 1) / warmup_steps, 1.0))

        # model

        self.model = model

        # ema model

        self.ema_model = None

        if self.accelerator.is_main_process:
            self.ema_model = EMA(
                model,
                beta = ema_decay_rate,
                update_model_with_ema_every = switch_ema_every,
                forward_method_names = ('predict',)
            )

        # recurrent and act related variables

        self.halt_prob_thres = halt_prob_thres
        self.max_recurrent_steps = max_recurrent_steps
        self.thinking_cost_weight = thinking_cost_weight

        # checkpoint settings
        self.checkpoint_dir = checkpoint_dir
        self.checkpoint_interval = checkpoint_interval
        
        if self.checkpoint_dir is not None:
            Path(self.checkpoint_dir).mkdir(parents=True, exist_ok=True)
            # –°—Ç–≤–æ—Ä–∏—Ç–∏ CheckpointManager –¥–ª—è best model tracking
            self.checkpoint_manager = CheckpointManager(path=self.checkpoint_dir, keep_last=5)
            # –î–æ–¥–∞—Ç–∏ CheckpointCallback
            self.callbacks.add(CheckpointCallback(
                checkpoint_dir=self.checkpoint_dir,
                checkpoint_interval=self.checkpoint_interval,
                checkpoint_manager=self.checkpoint_manager
            ))
        else:
            self.checkpoint_manager = None

        # prepare maybe distributed

        self.model, self.optim, self.dataloader, self.scheduler = self.accelerator.prepare(self.model, self.optim, self.dataloader, self.scheduler)
        
        # TrainState –¥–ª—è –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è —Å—Ç–∞–Ω—É –Ω–∞–≤—á–∞–Ω–Ω—è
        self.train_state = TrainState()
        
        # Best metrics tracking (–¥–ª—è best model checkpointing)
        self.best_loss: Optional[float] = None
        self.best_eval_score: Optional[float] = None
        self.best_entropy: Optional[float] = None

    def save_checkpoint(self, epoch: int, batch_idx: int, batch_count: int, is_final: bool = False):
        """
        –ó–±–µ—Ä–µ–≥—Ç–∏ checkpoint –Ω–∞–≤—á–∞–Ω–Ω—è
        
        Args:
            epoch: –ü–æ—Ç–æ—á–Ω–∞ –µ–ø–æ—Ö–∞
            batch_idx: –Ü–Ω–¥–µ–∫—Å –±–∞—Ç—á—É –≤ –µ–ø–æ—Å—ñ
            batch_count: –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –æ–±—Ä–æ–±–ª–µ–Ω–∏—Ö –±–∞—Ç—á—ñ–≤
            is_final: –ß–∏ —Ü–µ —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π checkpoint –ø—ñ—Å–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –Ω–∞–≤—á–∞–Ω–Ω—è
        """
        if self.checkpoint_dir is None or not self.accelerator.is_main_process:
            return
        
        checkpoint_path = Path(self.checkpoint_dir)
        
        # –°—Ç–≤–æ—Ä–∏—Ç–∏ —Å–ª–æ–≤–Ω–∏–∫ –∑—ñ —Å—Ç–∞–Ω–æ–º
        checkpoint_state = {
            'epoch': epoch,
            'batch_idx': batch_idx,
            'batch_count': batch_count,
            'model_state_dict': self.accelerator.get_state_dict(self.model),
            'optimizer_state_dict': self.accelerator.get_state_dict(self.optim),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'epochs': self.epochs,
            'batch_size': self.batch_size,
            'train_state': self.train_state.to_dict(),  # –ó–±–µ—Ä–µ–≥—Ç–∏ TrainState
        }
        
        # –ó–±–µ—Ä–µ–≥—Ç–∏ EMA –º–æ–¥–µ–ª—å —è–∫—â–æ –≤–æ–Ω–∞ —î
        if self.ema_model is not None:
            checkpoint_state['ema_model_state_dict'] = self.ema_model.ema_model.state_dict()
            checkpoint_state['ema_decay'] = self.ema_model.beta
        
        # –ó–±–µ—Ä–µ–≥—Ç–∏ checkpoint
        suffix = "final" if is_final else f"epoch_{epoch}_batch_{batch_idx}"
        checkpoint_file = checkpoint_path / f"checkpoint_{suffix}.pt"
        
        torch.save(checkpoint_state, checkpoint_file)
        
        # –¢–∞–∫–æ–∂ –∑–±–µ—Ä–µ–≥—Ç–∏ —è–∫ "latest" checkpoint
        latest_file = checkpoint_path / "checkpoint_latest.pt"
        torch.save(checkpoint_state, latest_file)
        
        self.accelerator.print(f"üíæ Checkpoint –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {checkpoint_file.name}")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —Ç–∞ –∑–±–µ—Ä–µ–≥—Ç–∏ best checkpoints —á–µ—Ä–µ–∑ CheckpointCallback
        if self.accelerator.is_main_process:
            checkpoint_callbacks = [cb for cb in self.callbacks.callbacks if isinstance(cb, CheckpointCallback)]
            for checkpoint_cb in checkpoint_callbacks:
                try:
                    checkpoint_cb.save_best_checkpoints(self.train_state, self.accelerator, self.model, self.optim)
                except Exception as e:
                    # –ù–µ –∑—É–ø–∏–Ω—è—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è —á–µ—Ä–µ–∑ –ø–æ–º–∏–ª–∫–∏ best checkpointing
                    if self.log_file:
                        self._log_to_file(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ best checkpointing: {e}")

    def load_checkpoint(self, checkpoint_path: str | Path):
        """
        –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ checkpoint –Ω–∞–≤—á–∞–Ω–Ω—è
        
        Args:
            checkpoint_path: –®–ª—è—Ö –¥–æ checkpoint —Ñ–∞–π–ª—É
            
        Returns:
            tuple: (epoch, batch_idx, batch_count) –¥–ª—è –ø—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è –Ω–∞–≤—á–∞–Ω–Ω—è
        """
        checkpoint_path = Path(checkpoint_path)
        
        if not checkpoint_path.exists():
            raise FileNotFoundError(f"Checkpoint –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {checkpoint_path}")
        
        self.accelerator.print(f"üìÇ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è checkpoint: {checkpoint_path}")
        
        checkpoint = torch.load(checkpoint_path, map_location=self.accelerator.device)
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å—Ç–∞–Ω –º–æ–¥–µ–ª—ñ
        self.model.load_state_dict(checkpoint['model_state_dict'])
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ optimizer —Ç–∞ scheduler
        self.optim.load_state_dict(checkpoint['optimizer_state_dict'])
        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ EMA –º–æ–¥–µ–ª—å —è–∫—â–æ –≤–æ–Ω–∞ —î
        if self.ema_model is not None and 'ema_model_state_dict' in checkpoint:
            self.ema_model.ema_model.load_state_dict(checkpoint['ema_model_state_dict'])
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ TrainState —è–∫—â–æ –≤—ñ–Ω —î
        if 'train_state' in checkpoint:
            self.train_state = TrainState.from_dict(checkpoint['train_state'])
            epoch = self.train_state.epoch
            batch_idx = self.train_state.batch_idx
            batch_count = self.train_state.step
        else:
            # Fallback –¥–ª—è —Å—Ç–∞—Ä–∏—Ö checkpoint'—ñ–≤
            epoch = checkpoint.get('epoch', 1)
            batch_idx = checkpoint.get('batch_idx', 0)
            batch_count = checkpoint.get('batch_count', 0)
            # –û–Ω–æ–≤–∏—Ç–∏ TrainState
            self.train_state.update(epoch=epoch, batch_idx=batch_idx, step=batch_count)
        
        self.accelerator.print(f"‚úÖ Checkpoint –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: –µ–ø–æ—Ö–∞ {epoch}, –±–∞—Ç—á {batch_idx}, –∑–∞–≥–∞–ª–æ–º {batch_count} –±–∞—Ç—á—ñ–≤")
        
        return epoch, batch_idx, batch_count

    def forward(self, resume_from_checkpoint: str | Path | None = None):
        total_batches = len(self.dataloader) * self.epochs
        start_time = time.time()
        batch_count = 0
        start_epoch = 1
        start_batch_idx = 0
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ checkpoint —è–∫—â–æ –≤–∫–∞–∑–∞–Ω–æ
        if resume_from_checkpoint is not None:
            start_epoch, start_batch_idx, batch_count = self.load_checkpoint(resume_from_checkpoint)
            # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç–∏ –±–∞—Ç—á—ñ –¥–æ start_batch_idx
            self.accelerator.print(f"–ü—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è –∑ –µ–ø–æ—Ö–∏ {start_epoch}, –±–∞—Ç—á {start_batch_idx}")

        # –°—Ç–≤–æ—Ä–∏—Ç–∏ –ø—Ä–æ–≥—Ä–µ—Å-–±–∞—Ä —è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∏–π
        if HAS_TQDM and self.accelerator.is_main_process:
            initial_n = batch_count
            pbar = tqdm(total=total_batches, initial=initial_n, desc="–ù–∞–≤—á–∞–Ω–Ω—è", unit="batch",
                      bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')

        try:
            # Callback: on_train_start
            self.callbacks.on_train_start(self.train_state)
            
            for epoch in range(start_epoch, self.epochs + 1):
                epoch_start = time.time()
                
                # –û–Ω–æ–≤–∏—Ç–∏ TrainState –¥–ª—è –µ–ø–æ—Ö–∏
                self.train_state.update(epoch=epoch)
                
                # Callback: on_epoch_start
                self.callbacks.on_epoch_start(self.train_state)
                
                # –õ–æ–≥—É–≤–∞–Ω–Ω—è –ø–æ—Ç–æ—á–Ω–æ–≥–æ curriculum stage (—á–µ—Ä–µ–∑ callback)
                if self.curriculum_scheduler is not None and self.accelerator.is_main_process:
                    stage_desc = self.curriculum_scheduler.describe()
                    self.accelerator.print(stage_desc)
                    if self.log_file:
                        self._log_to_file(stage_desc)
                
                if HAS_TQDM and self.accelerator.is_main_process:
                    pbar.set_description(f"–ï–ø–æ—Ö–∞ {epoch}/{self.epochs}")

                for batch_idx, batch_data in enumerate(self.dataloader):
                    # –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ document-aware dataset (–∑ doc_id, segment_id) —Ç–∞ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç—É
                    if len(batch_data) == 4:
                        dataset_input, dataset_output, doc_ids, segment_ids = batch_data
                        # doc_ids —Ç–∞ segment_ids –¥–æ—Å—Ç—É–ø–Ω—ñ, –∞–ª–µ –Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –Ω–∞–ø—Ä—è–º—É –≤ trainer
                        # –í–æ–Ω–∏ –º–æ–∂—É—Ç—å –±—É—Ç–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ –¥–ª—è document-aware –ª–æ–≥—ñ–∫–∏ –≤ –º–∞–π–±—É—Ç–Ω—å–æ–º—É
                    elif len(batch_data) == 2:
                        dataset_input, dataset_output = batch_data
                    else:
                        raise ValueError(f"–ù–µ–≤—ñ–¥–æ–º–∏–π —Ñ–æ—Ä–º–∞—Ç batch_data: –æ—á—ñ–∫—É—î—Ç—å—Å—è 2 –∞–±–æ 4 –µ–ª–µ–º–µ–Ω—Ç–∏, –æ—Ç—Ä–∏–º–∞–Ω–æ {len(batch_data)}")
                    # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç–∏ –±–∞—Ç—á—ñ –¥–æ start_batch_idx –¥–ª—è –ø–µ—Ä—à–æ—ó –µ–ø–æ—Ö–∏ –ø—ñ—Å–ª—è resume
                    if epoch == start_epoch and batch_idx < start_batch_idx:
                        # –û–Ω–æ–≤–∏—Ç–∏ –ø—Ä–æ–≥—Ä–µ—Å-–±–∞—Ä –Ω–∞–≤—ñ—Ç—å –¥–ª—è –ø—Ä–æ–ø—É—â–µ–Ω–∏—Ö –±–∞—Ç—á—ñ–≤
                        if HAS_TQDM and self.accelerator.is_main_process:
                            pbar.update(1)
                        continue
                    
                    outputs, latents = self.model.get_initial()

                    # –ó–±–µ—Ä–µ–≥—Ç–∏ –ø–æ—Ç–æ—á–Ω–∏–π loss –¥–ª—è –≤–∏–≤–æ–¥—É –≤ –ª–æ–≥
                    current_main_loss = None
                    actual_recurrent_steps = 0  # –§–∞–∫—Ç–∏—á–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏—Ö recurrent steps
                    
                    # –î–æ–¥–∞—Ç–∏ —Ç–∞–π–º–µ—Ä –¥–ª—è –≤–∏—è–≤–ª–µ–Ω–Ω—è –∑–∞–≤–∏—Å–∞–Ω–Ω—è
                    # –ó–±—ñ–ª—å—à–µ–Ω—ñ —Ç–∞–π–º–∞—É—Ç–∏ –¥–ª—è –ø–æ–≤—ñ–ª—å–Ω–∏—Ö —Å–∏—Å—Ç–µ–º –∑ swap
                    batch_start_time = time.time()
                    max_batch_time = 3600  # –ú–∞–∫—Å–∏–º—É–º 60 —Ö–≤–∏–ª–∏–Ω –Ω–∞ –±–∞—Ç—á (–¥–ª—è –ø–æ–≤—ñ–ª—å–Ω–∏—Ö —Å–∏—Å—Ç–µ–º)
                    step_start_time = time.time()
                    max_step_time = 600  # –ú–∞–∫—Å–∏–º—É–º 10 —Ö–≤–∏–ª–∏–Ω –Ω–∞ recurrent step (–¥–ª—è —Å–∏—Å—Ç–µ–º –∑ swap)
                    
                    # –ü–æ—á–∞—Ç–∫–æ–≤–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–∫–µ–Ω—ñ–≤ –¥–ª—è –æ–±—á–∏—Å–ª–µ–Ω–Ω—è tokens_per_sec
                    initial_tokens = dataset_input.numel()
                    
                    # –û–Ω–æ–≤–∏—Ç–∏ TrainState –Ω–∞ –ø–æ—á–∞—Ç–∫—É –±–∞—Ç—á–∞
                    self.train_state.update(
                        epoch=epoch,
                        batch_idx=batch_idx,
                        step=batch_count
                    )
                    
                    for recurrent_step in range_from_one(self.max_recurrent_steps):
                        actual_recurrent_steps = recurrent_step
                        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –∑–∞–≤–∏—Å–∞–Ω–Ω—è –≤ –æ–∫—Ä–µ–º–æ–º—É step
                        step_elapsed = time.time() - step_start_time
                        if step_elapsed > max_step_time:
                            warning_msg = f"‚ö†Ô∏è –£–í–ê–ì–ê: Recurrent step {recurrent_step} –ø—Ä–∞—Ü—é—î –≤–∂–µ {step_elapsed:.0f} —Å–µ–∫—É–Ω–¥ (> {max_step_time}s)!\n   –ï–ø–æ—Ö–∞: {epoch}, –ë–∞—Ç—á: {batch_idx}\n   üî¥ –ü–†–ò–ú–£–°–û–í–ò–ô –í–ò–•–Ü–î –∑ recurrent_steps —Ü–∏–∫–ª—É –¥–ª—è –∑–∞–ø–æ–±—ñ–≥–∞–Ω–Ω—è –∑–∞–≤–∏—Å–∞–Ω–Ω—è"
                            self.accelerator.print(warning_msg)
                            if self.log_file:
                                self._log_to_file(warning_msg)
                            break
                        
                        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –∑–∞–≤–∏—Å–∞–Ω–Ω—è –≤—Å—å–æ–≥–æ –±–∞—Ç—á–∞
                        batch_elapsed = time.time() - batch_start_time
                        if batch_elapsed > max_batch_time:
                            warning_msg = f"‚ö†Ô∏è –£–í–ê–ì–ê: –ë–∞—Ç—á {batch_idx} –ø—Ä–∞—Ü—é—î –≤–∂–µ {batch_elapsed:.0f} —Å–µ–∫—É–Ω–¥ (> {max_batch_time}s). –ú–æ–∂–ª–∏–≤–µ –∑–∞–≤–∏—Å–∞–Ω–Ω—è!\n   –ï–ø–æ—Ö–∞: {epoch}, recurrent_step: {recurrent_step}/{self.max_recurrent_steps}\n   üî¥ –ü–†–ò–ú–£–°–û–í–ò–ô –í–ò–•–Ü–î –∑ –±–∞—Ç—á–∞ –¥–ª—è –∑–∞–ø–æ–±—ñ–≥–∞–Ω–Ω—è –∑–∞–≤–∏—Å–∞–Ω–Ω—è"
                            self.accelerator.print(warning_msg)
                            if self.log_file:
                                self._log_to_file(warning_msg)
                            break
                        
                        step_start_time = time.time()  # –û–Ω–æ–≤–∏—Ç–∏ —á–∞—Å –ø–æ—á–∞—Ç–∫—É step
                        
                        loss, (main_loss, halt_loss), outputs, latents, pred, halt = self.model(dataset_input, outputs, latents, labels = dataset_output)
                        current_main_loss = main_loss.mean().item()  # –ó–±–µ—Ä–µ–≥—Ç–∏ –¥–ª—è –≤–∏–≤–æ–¥—É
                        
                        # Thinking cost: –∑ adaptive recursion gate –∞–±–æ –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π
                        if hasattr(self.model, 'adaptive_recursion') and self.model.adaptive_recursion:
                            # –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ adaptive recursion gate –¥–ª—è thinking cost
                            # –ü–æ—Ç—Ä—ñ–±–Ω–æ –æ—Ç—Ä–∏–º–∞—Ç–∏ hidden representation –¥–ª—è –æ–±—á–∏—Å–ª–µ–Ω–Ω—è gate
                            # –Ø–∫—â–æ outputs –¥–æ—Å—Ç—É–ø–Ω—ñ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —ó—Ö –¥–ª—è –æ–±—á–∏—Å–ª–µ–Ω–Ω—è gate
                            if outputs.numel() > 0:
                                # –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ outputs –Ω–∞–ø—Ä—è–º—É –¥–ª—è gate (gate network —Å–∞–º –∑—Ä–æ–±–∏—Ç—å reduce)
                                gate = self.model.compute_adaptive_depth(outputs)  # [batch_size]
                                # Thinking cost = weight * gate * normalized_step
                                # Gate –≤–∫–∞–∑—É—î —Å–∫—ñ–ª—å–∫–∏ "–¥—É–º–∞—Ç–∏", —Ç–æ–º—É –º–Ω–æ–∂–∏–º–æ –Ω–∞ –Ω—å–æ–≥–æ
                                normalized_step = recurrent_step / self.max_recurrent_steps
                                thinking_cost_per_sample = self.thinking_cost_weight * gate * normalized_step
                                # Loss —Ü–µ sum –ø–æ batch, —Ç–æ–º—É –¥–æ–¥–∞—î–º–æ sum thinking cost
                                thinking_cost_scalar = thinking_cost_per_sample.sum().item()
                            else:
                                # Fallback –¥–æ –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–æ—ó —Ñ–æ—Ä–º—É–ª–∏
                                thinking_cost_scalar = self.thinking_cost_weight * (recurrent_step / self.max_recurrent_steps)
                        else:
                            # –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —Ñ–æ—Ä–º—É–ª–∞ (–∫–æ–ª–∏ adaptive recursion –≤–∏–º–∫–Ω–µ–Ω–æ)
                            # Thinking cost = weight * (recurrent_step / max_recurrent_steps)
                            thinking_cost_scalar = self.thinking_cost_weight * (recurrent_step / self.max_recurrent_steps)
                        
                        # –î–æ–¥–∞—Ç–∏ thinking cost –¥–æ loss (loss —Ü–µ sum –ø–æ batch, —Ç–æ–º—É –¥–æ–¥–∞—î–º–æ —Å–∫–∞–ª—è—Ä)
                        thinking_cost_tensor = torch.tensor(thinking_cost_scalar, device=loss.device, dtype=loss.dtype)
                        loss = loss + thinking_cost_tensor
                        
                        # –û–±—á–∏—Å–ª–∏—Ç–∏ entropy –¥–ª—è best checkpointing (SECONDARY –º–µ—Ç—Ä–∏–∫–∞)
                        import torch.nn.functional as F
                        probs = F.softmax(pred, dim=-1)
                        entropy = -(probs * torch.log(probs + 1e-10)).sum(dim=-1).mean().item()
                        
                        # –û–Ω–æ–≤–∏—Ç–∏ TrainState –∑ –ø–æ—Ç–æ—á–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏
                        self.train_state.update(
                            loss=current_main_loss,
                            main_loss=current_main_loss,
                            halt_loss=halt_loss.mean().item() if halt_loss.numel() > 0 else 0.0,
                            thinking_cost=thinking_cost_scalar,
                            recursion_depth=recurrent_step,
                            actual_recurrent_steps=actual_recurrent_steps
                        )
                        # –ó–±–µ—Ä—ñ–≥–∞—Ç–∏ entropy –≤ metadata –¥–ª—è best checkpointing
                        if 'entropy' not in self.train_state.metadata:
                            self.train_state.metadata['entropy'] = []
                        self.train_state.metadata['entropy'].append(entropy)
                        
                        # –õ–æ–≥—É–≤–∞–Ω–Ω—è –∫–æ–∂–Ω—ñ 5 –∫—Ä–æ–∫—ñ–≤ –¥–ª—è –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ (–∑–º–µ–Ω—à–µ–Ω–æ —á–∞—Å—Ç–æ—Ç—É)
                        if recurrent_step % 5 == 0 and self.accelerator.is_main_process:
                            halt_mean = halt.mean().item() if halt.numel() > 0 else 0.0
                            self.accelerator.print(f'   [Step {recurrent_step}/{self.max_recurrent_steps}] loss: {main_loss.mean().item():.3f} | halt: {halt_mean:.3f} | thinking_cost: {thinking_cost_scalar:.4f} | halt_thres: {self.halt_prob_thres}', flush=True)

                        # –û–Ω–æ–≤–∏—Ç–∏ –ø—Ä–æ–≥—Ä–µ—Å-–±–∞—Ä
                        if HAS_TQDM and self.accelerator.is_main_process:
                            elapsed = time.time() - start_time
                            if batch_count > 0:
                                avg_time = elapsed / batch_count
                                remaining = avg_time * (total_batches - batch_count)
                                pbar.set_postfix({
                                    'Loss': f"{main_loss.mean().item():.3f}",
                                    'Halt': f"{halt_loss.mean().item():.3f}",
                                    'ETA': f"{timedelta(seconds=int(remaining))}"
                                })
                            pbar.update(1)
                        else:
                            self.accelerator.print(f'[{epoch} ({recurrent_step} / {self.max_recurrent_steps})] loss: {main_loss.mean().item():.3f} | halt loss: {halt_loss.mean().item():.3f}')

                        self.accelerator.backward(loss)

                        self.optim.step()
                        self.optim.zero_grad()

                        self.scheduler.step()

                        if self.accelerator.is_main_process:
                            self.ema_model.update()

                        # handle halting

                        halt_mask = halt >= self.halt_prob_thres

                        if not halt_mask.any():
                            # –Ø–∫—â–æ —Ü–µ –æ—Å—Ç–∞–Ω–Ω—ñ–π –∫—Ä–æ–∫, –ø—Ä–∏–º—É—Å–æ–≤–æ –≤–∏–π—Ç–∏
                            if recurrent_step == self.max_recurrent_steps:
                                if self.accelerator.is_main_process:
                                    warning_msg = f'   ‚ö†Ô∏è –î–æ—Å—è–≥–Ω—É—Ç–æ max_recurrent_steps ({self.max_recurrent_steps}) –±–µ–∑ halt. –ü—Ä–∏–º—É—Å–æ–≤–∏–π –≤–∏—Ö—ñ–¥.'
                                    self.accelerator.print(warning_msg)
                                    if self.log_file:
                                        self._log_to_file(warning_msg)
                                break
                            continue

                        # –ó–±–µ—Ä–µ–≥—Ç–∏ —Å—Ç–∞—Ä—ñ —Ç–µ–Ω–∑–æ—Ä–∏ –ø–µ—Ä–µ–¥ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—î—é –¥–ª—è –æ—á–∏—â–µ–Ω–Ω—è –ø–∞–º'—è—Ç—ñ
                        old_outputs, old_latents = outputs, latents
                        
                        outputs = outputs[~halt_mask]
                        latents = latents[~halt_mask]
                        dataset_input = dataset_input[~halt_mask]
                        dataset_output = dataset_output[~halt_mask]
                        
                        # –û—á–∏—Å—Ç–∏—Ç–∏ –ø–∞–º'—è—Ç—å –≤—ñ–¥ —Å—Ç–∞—Ä–∏—Ö —Ç–µ–Ω–∑–æ—Ä—ñ–≤
                        del old_outputs, old_latents
                        if hasattr(torch.cuda, 'empty_cache'):
                            torch.cuda.empty_cache()

                        if is_empty(outputs):
                            if self.accelerator.is_main_process:
                                self.accelerator.print(f'   ‚úÖ –í—Å—ñ –ø—Ä–∏–∫–ª–∞–¥–∏ –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—è (halt) –Ω–∞ step {recurrent_step}')
                            break
                    
                    batch_count += 1
                    
                    # –û–±—á–∏—Å–ª–∏—Ç–∏ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –±–∞—Ç—á–∞
                    batch_duration = time.time() - batch_start_time
                    
                    # –û–±—á–∏—Å–ª–∏—Ç–∏ tokens_per_sec
                    tokens_per_sec = None
                    if batch_duration > 0 and initial_tokens > 0:
                        tokens_per_sec = initial_tokens / batch_duration
                    
                    # –û–Ω–æ–≤–∏—Ç–∏ TrainState –∑ batch metrics
                    self.train_state.update(
                        step=batch_count,
                        batch_idx=batch_idx,
                        tokens_per_sec=tokens_per_sec
                    )
                    if tokens_per_sec is not None:
                        self.train_state.metadata['tokens_per_sec'] = tokens_per_sec
                    
                    # Callback: on_batch_end (–≤–∫–ª—é—á–∞—î –ª–æ–≥—É–≤–∞–Ω–Ω—è)
                    self.callbacks.on_batch_end(self.train_state)
                    
                    # –ó–±–µ—Ä–µ–≥—Ç–∏ best checkpoints –Ω–∞ –∫–æ–∂–Ω–æ–º—É –±–∞—Ç—á—ñ (—è–∫—â–æ –Ω–æ–≤–∏–π best)
                    # –¶–µ –≤–∞–∂–ª–∏–≤–æ, —â–æ–± –Ω–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–∏ –Ω–∞–π–∫—Ä–∞—â—É –º–æ–¥–µ–ª—å
                    if self.accelerator.is_main_process and self.checkpoint_manager is not None:
                        checkpoint_callbacks = [cb for cb in self.callbacks.callbacks if isinstance(cb, CheckpointCallback)]
                        for checkpoint_cb in checkpoint_callbacks:
                            try:
                                checkpoint_cb.save_best_checkpoints(self.train_state, self.accelerator, self.model, self.optim)
                            except Exception as e:
                                # –ù–µ –∑—É–ø–∏–Ω—è—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è —á–µ—Ä–µ–∑ –ø–æ–º–∏–ª–∫–∏ best checkpointing
                                if self.log_file:
                                    self._log_to_file(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ best checkpointing –Ω–∞ –±–∞—Ç—á—ñ {batch_idx}: {e}")
                    
                    # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –ø–µ—Ä—ñ–æ–¥–∏—á–Ω–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è checkpoint (—á–µ—Ä–µ–∑ callback)
                    checkpoint_callbacks = [cb for cb in self.callbacks.callbacks if isinstance(cb, CheckpointCallback)]
                    for checkpoint_cb in checkpoint_callbacks:
                        if checkpoint_cb.should_save_periodic(self.train_state):
                            if self.accelerator.is_main_process:
                                self.save_checkpoint(epoch, batch_idx, batch_count, is_final=False)
                    
                    # –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å—ñ–≤ (—è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∏–π)
                    if self.resource_monitor is not None and self.accelerator.is_main_process:
                        try:
                            resource_info = self.resource_monitor.check_resources(
                                batch_idx=batch_idx,
                                epoch=epoch,
                                batch_time=batch_duration
                            )
                            # –õ–æ–≥—É–≤–∞—Ç–∏ –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è —è–∫—â–æ —î
                            if resource_info.get('warnings'):
                                for warning in resource_info['warnings']:
                                    warning_msg = f"‚ö†Ô∏è {warning} (–ï–ø–æ—Ö–∞: {epoch}, –ë–∞—Ç—á: {batch_idx})"
                                    self.accelerator.print(warning_msg)
                                    if self.log_file:
                                        self._log_to_file(warning_msg)
                            
                            # Auto-reaction: –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å —Ä–µ—Å—É—Ä—Å—ñ–≤
                            recommendations = self.resource_monitor.auto_throttle(self.batch_size)
                            
                            # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑–º–µ–Ω—à–∏—Ç–∏ batch size
                            if recommendations.get('shrink_batch', False) and recommendations.get('batch_size_changed', False):
                                new_batch_size = recommendations.get('suggested_batch_size', self.batch_size)
                                if new_batch_size < self.batch_size:
                                    old_batch_size = self.batch_size
                                    self.batch_size = max(1, new_batch_size)  # –ú—ñ–Ω—ñ–º—É–º 1
                                    shrink_msg = f"üîß Auto-throttle: –∑–º–µ–Ω—à–µ–Ω–æ batch_size –∑ {old_batch_size} –¥–æ {self.batch_size} (–≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –ø–∞–º'—è—Ç—ñ: {recommendations.get('memory_percent', 0):.1f}%)"
                                    self.accelerator.print(shrink_msg)
                                    if self.log_file:
                                        self._log_to_file(shrink_msg)
                                    # –û–Ω–æ–≤–∏—Ç–∏ DataLoader –∑ –Ω–æ–≤–∏–º batch_size (–Ω–∞—Å—Ç—É–ø–Ω–∏–π –±–∞—Ç—á)
                                    # –ü—Ä–∏–º—ñ—Ç–∫–∞: DataLoader –æ–Ω–æ–≤–∏—Ç—å—Å—è –Ω–∞ –Ω–∞—Å—Ç—É–ø–Ω—ñ–π —ñ—Ç–µ—Ä–∞—Ü—ñ—ó
                            
                            # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ –ø–æ—Ç—Ä—ñ–±–Ω–æ –ø—Ä–∏–∑—É–ø–∏–Ω–∏—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è
                            if recommendations.get('pause', False):
                                pause_msg = f"‚è∏Ô∏è Auto-pause: –Ω–∞–≤—á–∞–Ω–Ω—è –ø—Ä–∏–∑—É–ø–∏–Ω–µ–Ω–æ —á–µ—Ä–µ–∑ –∫—Ä–∏—Ç–∏—á–Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —Ä–µ—Å—É—Ä—Å—ñ–≤ (CPU: {recommendations.get('cpu_usage', 0):.1f}%, Memory: {recommendations.get('memory_percent', 0):.1f}%)"
                                self.accelerator.print(pause_msg)
                                if self.log_file:
                                    self._log_to_file(pause_msg)
                                # –ü—Ä–∏–∑—É–ø–∏–Ω–∏—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è - –∑–±–µ—Ä–µ–≥—Ç–∏ checkpoint —Ç–∞ –≤–∏–π—Ç–∏
                                if self.checkpoint_dir is not None:
                                    self.save_checkpoint(epoch, batch_idx, batch_count, is_final=False)
                                raise RuntimeError("–ù–∞–≤—á–∞–Ω–Ω—è –ø—Ä–∏–∑—É–ø–∏–Ω–µ–Ω–æ —á–µ—Ä–µ–∑ –∫—Ä–∏—Ç–∏—á–Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —Ä–µ—Å—É—Ä—Å—ñ–≤")
                            
                            # –õ–æ–≥—É–≤–∞—Ç–∏ throttle —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó —è–∫—â–æ —î
                            if recommendations.get('throttle', False):
                                throttle_msg = f"‚ö° Auto-throttle –∞–∫—Ç–∏–≤–æ–≤–∞–Ω–æ (CPU: {recommendations.get('cpu_usage', 0):.1f}%, Memory: {recommendations.get('memory_percent', 0):.1f}%)"
                                if self.log_file:
                                    self._log_to_file(throttle_msg)
                                
                        except RuntimeError as e:
                            # –ü–æ–º–∏–ª–∫–∞ pause - –ø—Ä–æ–∫–∏–Ω—É—Ç–∏ –¥–∞–ª—ñ
                            raise
                        except Exception as e:
                            # –ù–µ –∑—É–ø–∏–Ω—è—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è —á–µ—Ä–µ–∑ –ø–æ–º–∏–ª–∫–∏ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É
                            error_msg = f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É —Ä–µ—Å—É—Ä—Å—ñ–≤: {e}"
                            if self.log_file:
                                self._log_to_file(error_msg)
                    
                    # –õ–æ–≥—É–≤–∞–Ω–Ω—è —Ç—Ä–∏–≤–∞–ª–æ—Å—Ç—ñ –±–∞—Ç—á–∞ (–¥–µ—Ç–∞–ª—å–Ω–µ)
                    if self.accelerator.is_main_process and batch_duration > 60:  # –Ø–∫—â–æ –±–∞—Ç—á —Ç—Ä–∏–≤–∞–≤ –±—ñ–ª—å—à–µ —Ö–≤–∏–ª–∏–Ω–∏
                        duration_msg = f"‚è±Ô∏è –ë–∞—Ç—á {batch_idx} (–ï–ø–æ—Ö–∞ {epoch}) —Ç—Ä–∏–≤–∞–≤ {batch_duration:.1f} —Å–µ–∫—É–Ω–¥"
                        if self.log_file:
                            self._log_to_file(duration_msg)
                    
                    # –ü–µ—Ä—ñ–æ–¥–∏—á–Ω–µ –æ—á–∏—â–µ–Ω–Ω—è –ø–∞–º'—è—Ç—ñ (–∫–æ–∂–Ω—ñ 10 –±–∞—Ç—á—ñ–≤)
                    if batch_count % 10 == 0:
                        import gc
                        gc.collect()
                        if hasattr(torch.cuda, 'empty_cache'):
                            torch.cuda.empty_cache()
                    
                    # –í–∏–≤–µ—Å—Ç–∏ –ø—Ä–æ–≥—Ä–µ—Å –≤ –ª–æ–≥-—Ñ–∞–π–ª (–¥–ª—è –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É)
                    # –í–∏–≤–æ–¥–∏–º–æ –∫–æ–∂–Ω—ñ 5 –±–∞—Ç—á—ñ–≤ –¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó (–∑–∞–º—ñ—Å—Ç—å –∫–æ–∂–Ω–æ–≥–æ)
                    if self.accelerator.is_main_process and (batch_count % 5 == 0 or batch_count == 1):
                        progress_pct = (batch_count / total_batches) * 100
                        elapsed = time.time() - start_time
                        if batch_count > 0:
                            avg_time = elapsed / batch_count
                            remaining = avg_time * (total_batches - batch_count)
                            loss_value = current_main_loss if current_main_loss is not None else 0.0
                            # –í–∏–≤–µ—Å—Ç–∏ –≤ stdout (—è–∫–∏–π –±—É–¥–µ –∑–∞–ø–∏—Å–∞–Ω–æ –≤ –ª–æ–≥ —á–µ—Ä–µ–∑ tee)
                            print(
                                f'üìä –ü—Ä–æ–≥—Ä–µ—Å: {batch_count}/{total_batches} –±–∞—Ç—á—ñ–≤ ({progress_pct:.1f}%) | '
                                f'–ï–ø–æ—Ö–∞: {epoch}/{self.epochs} | '
                                f'Loss: {loss_value:.3f} | '
                                f'ETA: {timedelta(seconds=int(remaining))}',
                                flush=True
                            )
                    
                    # –ó–±–µ—Ä–µ–≥—Ç–∏ checkpoint –ø–µ—Ä—ñ–æ–¥–∏—á–Ω–æ
                    if (self.checkpoint_dir is not None and 
                        batch_count % self.checkpoint_interval == 0 and
                        self.accelerator.is_main_process):
                        self.save_checkpoint(epoch, batch_idx, batch_count, is_final=False)
                    
                    # –í–∏–≤–µ—Å—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –µ–ø–æ—Ö–∏
                    if not HAS_TQDM and self.accelerator.is_main_process:
                        epoch_elapsed = time.time() - epoch_start
                        progress = (batch_idx + 1) / len(self.dataloader) * 100
                        self.accelerator.print(f'–ï–ø–æ—Ö–∞ {epoch}: {progress:.1f}% | –ß–∞—Å: {timedelta(seconds=int(epoch_elapsed))}')
                
                # –û–Ω–æ–≤–∏—Ç–∏ curriculum scheduler –ø—ñ—Å–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –µ–ø–æ—Ö–∏
                if self.curriculum_scheduler is not None:
                    self.curriculum_scheduler.on_epoch_end()

            if HAS_TQDM and self.accelerator.is_main_process:
                pbar.close()
            
            total_time = time.time() - start_time
            completion_msg = f'\n‚úÖ –ù–∞–≤—á–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {timedelta(seconds=int(total_time))}'
            self.accelerator.print(completion_msg)
            if self.log_file:
                self._log_to_file(completion_msg)
        
        except KeyboardInterrupt:
            interrupt_msg = "\n‚ö†Ô∏è –ù–∞–≤—á–∞–Ω–Ω—è –ø–µ—Ä–µ—Ä–≤–∞–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º (KeyboardInterrupt)"
            self.accelerator.print(interrupt_msg)
            if self.log_file:
                self._log_to_file(interrupt_msg)
            # –ó–±–µ—Ä–µ–≥—Ç–∏ checkpoint –ø–µ—Ä–µ–¥ –≤–∏—Ö–æ–¥–æ–º
            if self.checkpoint_dir is not None and self.accelerator.is_main_process:
                self.save_checkpoint(epoch, batch_idx, batch_count, is_final=False)
            raise
        
        except Exception as e:
            # –î–µ—Ç–∞–ª—å–Ω–æ –∑–∞–ª–æ–≥—É–≤–∞—Ç–∏ –ø–æ–º–∏–ª–∫—É
            batch_idx_str = str(batch_idx) if 'batch_idx' in locals() else "unknown"
            self._log_error(e, f"–ø—ñ–¥ —á–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è (–ï–ø–æ—Ö–∞: {epoch}, –ë–∞—Ç—á: {batch_idx_str})")
            # –ó–±–µ—Ä–µ–≥—Ç–∏ checkpoint –ø–µ—Ä–µ–¥ –≤–∏—Ö–æ–¥–æ–º
            if self.checkpoint_dir is not None and self.accelerator.is_main_process:
                try:
                    self.save_checkpoint(epoch, batch_idx, batch_count, is_final=False)
                except Exception as checkpoint_error:
                    self._log_error(checkpoint_error, "–ø—Ä–∏ —Å–ø—Ä–æ–±—ñ –∑–±–µ—Ä–µ–≥—Ç–∏ checkpoint –ø—ñ—Å–ª—è –ø–æ–º–∏–ª–∫–∏")
            raise
    
    def _log_to_file(self, message: str):
        """–ó–∞–ø–∏—Å–∞—Ç–∏ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤ –ª–æ–≥-—Ñ–∞–π–ª"""
        if self.log_file and self.accelerator.is_main_process:
            timestamp = time.strftime('%Y-%m-%d %H:%M:%S')
            try:
                with open(self.log_file, 'a', encoding='utf-8') as f:
                    f.write(f"[{timestamp}] {message}\n")
            except Exception as e:
                # –ù–µ –∑—É–ø–∏–Ω—è—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è —á–µ—Ä–µ–∑ –ø–æ–º–∏–ª–∫–∏ –∑–∞–ø–∏—Å—É –≤ –ª–æ–≥
                print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∑–∞–ø–∏—Å—É –≤ –ª–æ–≥-—Ñ–∞–π–ª: {e}")
    
    def _log_error(self, error: Exception, context: str = ""):
        """–î–µ—Ç–∞–ª—å–Ω–æ –∑–∞–ª–æ–≥—É–≤–∞—Ç–∏ –ø–æ–º–∏–ª–∫—É –∑ –ø–æ–≤–Ω–∏–º traceback"""
        import traceback
        error_msg = f"[ERROR] –ü–û–ú–ò–õ–ö–ê{': ' + context if context else ''}: {str(error)}"
        traceback_str = traceback.format_exc()
        
        self.accelerator.print(error_msg)
        self.accelerator.print(traceback_str)
        
        if self.log_file:
            self._log_to_file(error_msg)
            self._log_to_file("Traceback:")
            self._log_to_file(traceback_str)

        if self.accelerator.is_main_process:
            self.ema_model.copy_params_from_ema_to_model()
            
            # Callback: on_train_end (–≤–∫–ª—é—á–∞—î –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ñ—ñ–Ω–∞–ª—å–Ω–æ–≥–æ checkpoint)
            self.callbacks.on_train_end(self.train_state)
            
            # –ó–±–µ—Ä–µ–≥—Ç–∏ —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π checkpoint
            if self.checkpoint_dir is not None and self.accelerator.is_main_process:
                self.save_checkpoint(self.epochs, len(self.dataloader) - 1, batch_count, is_final=True)
